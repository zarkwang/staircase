{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import optimize\n",
    "import DCM\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants who complete all PW tasks: 2671\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_excel('../ALP/alp481/ms481_weighted.xlsx')\n",
    "df_raw = df_raw[df_raw['reward'] >=0]\n",
    "\n",
    "# Questions about stock holding\n",
    "for var in ['q3','q4','q6','q7','q12','q13','q15','q16']:\n",
    "    df_raw[var] = df_raw[var].fillna(0)\n",
    "\n",
    "# Some participants do not recall the exact amounts\n",
    "# These participants are directed to a follow-up question: selecting from pre-defined ranges  \n",
    "# rough_stock_holding = {1:0, 2: 500, 3: 2500, 4: 5000, 5: 10000, 6:30000, 7:100000, 8:200000}\n",
    "\n",
    "rough_stock_holding = {\n",
    "    1: (0, 500),\n",
    "    2: (501, 2500),\n",
    "    3: (2501, 5000),\n",
    "    4: (5001, 10000),\n",
    "    5: (10001, 30000),\n",
    "    6: (30001, 100000),\n",
    "    7: (100001, 200000),\n",
    "    8: (200000, np.inf) \n",
    "}\n",
    "\n",
    "'''\n",
    "    1 Between $0 and $500 \n",
    "    2 Between $501 and $2,500 \n",
    "    3 Between $2,501 and $5,000\n",
    "    4 Between $5,001 and $10,000 \n",
    "    5 Between $10,001 and $30,000 \n",
    "    6 Between $30,001 and $100,000 \n",
    "    7 Between $100,001 and $200,000 \n",
    "    8 More than $200,000\n",
    "'''\n",
    "\n",
    "# Impute stock holding amounts by median of the collected exact amounts within the corresponding range\n",
    "wealth_vars = {'q3': 'fund', 'q6':'indiv_stock', 'q12':'retire_fund', 'q15':'retire_stock'}\n",
    "impute_holding = np.repeat(0, len(df_raw))\n",
    "\n",
    "for var in ['q3','q6','q12','q15']:\n",
    "\n",
    "    rough_var = 'q'+str(int(var[1:]) + 1)\n",
    "\n",
    "    for hold_level in range(1,9):\n",
    "        lower, upper = rough_stock_holding[hold_level]\n",
    "\n",
    "        holding = df_raw[(df_raw[var] > lower) & (df_raw[var] <= upper)][var].median()\n",
    "        \n",
    "        impute_holding = impute_holding + holding * (df_raw[rough_var] == hold_level)\n",
    "\n",
    "    df_raw[wealth_vars[var]] = df_raw[var].fillna(0) + impute_holding.fillna(0)\n",
    "\n",
    "# Ratio of equity in individual stocks\n",
    "df_raw['ratio_indiv_stock'] = df_raw['indiv_stock'] / (df_raw['indiv_stock'] + df_raw['fund'])\n",
    "\n",
    "# Total financial wealth\n",
    "df_raw['fin_wealth'] = df_raw['indiv_stock'] + df_raw['fund'] + df_raw['retire_stock'] + df_raw['retire_fund']\n",
    "\n",
    "\n",
    "# Get the variables for the risky choices\n",
    "# Each variable is formed as '{Task}_{Round}_{Node number}'\n",
    "# For example, 'a2_2_2' implies Task a2, Round 2, Node 2\n",
    "q_risk_vars = []\n",
    "for var in df_raw.columns:\n",
    "    if var.startswith('a') and len(var) > 1 and var[1].isdigit():\n",
    "        q_risk_vars.append(var)\n",
    "\n",
    "# Remove multiple choices\n",
    "# Round 1: if choice = 1, must jump to Node 3; if choice = 2, must jump to Node 2\n",
    "# Round 2, Node 2: if choice = 1, must jump to Node 5; if choice = 2, must jump to Node 4\n",
    "# Round 2, Node 3: if choice = 1, must jump to Node 7; if choice = 2, must jump to Node 6\n",
    "for q in q_risk_vars:\n",
    "\n",
    "    q_round = int(q.split('_')[1])\n",
    "\n",
    "    if q_round in [1,2]:\n",
    "        q_loc = int(q.split('_')[2])\n",
    "        if q_loc == 1:\n",
    "            current_choice = df_raw[f\"{q.split('_')[0]}_{q_round}_{q_loc}\"]\n",
    "            df_raw.loc[current_choice == 1, f\"{q.split('_')[0]}_{q_round+1}_2\"] == np.nan\n",
    "            df_raw.loc[current_choice == 2, f\"{q.split('_')[0]}_{q_round+1}_3\"] == np.nan\n",
    "        if q_loc == 2:\n",
    "                current_choice = df_raw[f\"{q.split('_')[0]}_{q_round}_{q_loc}\"]\n",
    "                df_raw.loc[current_choice == 1, f\"{q.split('_')[0]}_{q_round+1}_4\"] == np.nan\n",
    "                df_raw.loc[current_choice == 2, f\"{q.split('_')[0]}_{q_round+1}_5\"] == np.nan\n",
    "        if q_loc == 3:\n",
    "                current_choice = df_raw[f\"{q.split('_')[0]}_{q_round}_{q_loc}\"]\n",
    "                df_raw.loc[current_choice == 1, f\"{q.split('_')[0]}_{q_round+1}_6\"] == np.nan\n",
    "                df_raw.loc[current_choice == 2, f\"{q.split('_')[0]}_{q_round+1}_7\"] == np.nan\n",
    "\n",
    "\n",
    "# Calculate the choices for each specific question\n",
    "prefixes = list(set(col.rsplit('_', 1)[0] for col in q_risk_vars))\n",
    "\n",
    "for prefix in prefixes:\n",
    "    matching_cols = [col for col in q_risk_vars if col.startswith(prefix)]\n",
    "    df_raw[prefix] = df_raw[matching_cols].bfill(axis=1).iloc[:, 0]\n",
    "\n",
    "# Each row is an indidvidual-choice dyad\n",
    "df_risk_choice = df_raw[['prim_key']+prefixes].melt(id_vars='prim_key', var_name='q_risk', value_name='choice')\n",
    "\n",
    "# Only keep the participants who complete all 6 Probabilty Weighting (PW) tasks \n",
    "pw_tasks = ['a7', 'a8', 'a9', 'a10', 'a11', 'a12']\n",
    "pw_criteria = df_risk_choice['q_risk'].str.startswith(tuple(pw_tasks)) & \\\n",
    "                df_risk_choice['q_risk'].str.split('_').str[1].isin(['1','2','3'])\n",
    "\n",
    "df_check = df_risk_choice[pw_criteria].groupby('prim_key').count()['choice']\n",
    "\n",
    "df_risk_choice = df_risk_choice[df_risk_choice['prim_key'].isin(df_check[df_check == 18].index)]\n",
    "\n",
    "print('Number of participants who complete all PW tasks:',len(df_risk_choice['prim_key'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phd19zw1\\AppData\\Local\\Temp\\ipykernel_9828\\1594690173.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_risk_task['q_task'] = df_risk_task['q_risk'].str.split('_').str[0]\n",
      "C:\\Users\\phd19zw1\\AppData\\Local\\Temp\\ipykernel_9828\\1594690173.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_risk_task['q_round'] = df_risk_task['q_risk'].str.split('_').str[1]\n",
      "C:\\Users\\phd19zw1\\AppData\\Local\\Temp\\ipykernel_9828\\1594690173.py:17: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_all_tasks.replace({'A':1, 'B':2}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prim_key</th>\n",
       "      <th>underweight</th>\n",
       "      <th>overweight</th>\n",
       "      <th>riskaversion</th>\n",
       "      <th>inverse_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10017494:1</td>\n",
       "      <td>1.594</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.30300</td>\n",
       "      <td>1.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10018010:1</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.412</td>\n",
       "      <td>-0.01275</td>\n",
       "      <td>-0.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10027497:1</td>\n",
       "      <td>0.677</td>\n",
       "      <td>-0.637</td>\n",
       "      <td>0.01275</td>\n",
       "      <td>1.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10027500:1</td>\n",
       "      <td>1.886</td>\n",
       "      <td>1.036</td>\n",
       "      <td>0.25650</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10027505:1</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.20050</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>9117485:1</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.49675</td>\n",
       "      <td>-0.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>9117486:1</td>\n",
       "      <td>0.802</td>\n",
       "      <td>1.036</td>\n",
       "      <td>0.28925</td>\n",
       "      <td>-0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>9117488:1</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.23975</td>\n",
       "      <td>-1.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2669</th>\n",
       "      <td>9117489:1</td>\n",
       "      <td>1.594</td>\n",
       "      <td>0.859</td>\n",
       "      <td>-0.07025</td>\n",
       "      <td>0.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>9117490:1</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.482</td>\n",
       "      <td>-0.11975</td>\n",
       "      <td>0.318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2671 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        prim_key  underweight  overweight  riskaversion  inverse_S\n",
       "0     10017494:1        1.594       0.002       0.30300      1.592\n",
       "1     10018010:1       -0.102       0.412      -0.01275     -0.514\n",
       "2     10027497:1        0.677      -0.637       0.01275      1.314\n",
       "3     10027500:1        1.886       1.036       0.25650      0.850\n",
       "4     10027505:1        0.858       0.052      -0.20050      0.806\n",
       "...          ...          ...         ...           ...        ...\n",
       "2666   9117485:1        0.174       0.365       0.49675     -0.191\n",
       "2667   9117486:1        0.802       1.036       0.28925     -0.234\n",
       "2668   9117488:1       -0.484       0.656       0.23975     -1.140\n",
       "2669   9117489:1        1.594       0.859      -0.07025      0.735\n",
       "2670   9117490:1       -0.164      -0.482      -0.11975      0.318\n",
       "\n",
       "[2671 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_risk_task = df_risk_choice[df_risk_choice['q_risk'].str.split('_').str[1].isin(['1','2','3'])]\n",
    "df_risk_task['q_task'] = df_risk_task['q_risk'].str.split('_').str[0]\n",
    "df_risk_task['q_round'] = df_risk_task['q_risk'].str.split('_').str[1]\n",
    "\n",
    "# Each row is an individual-task dyad\n",
    "df_risk_task = df_risk_task.pivot_table(\n",
    "    index = ['prim_key','q_task'],\n",
    "    columns = 'q_round',\n",
    "    values = 'choice'\n",
    ").reset_index()\n",
    "\n",
    "df_risk_task.columns = ['prim_key','q_task','round1_choice','round2_choice','round3_choice']\n",
    "\n",
    "# Import the Bi-Section Paths for all tasks\n",
    "# choice = 1: Option A; choice = 2: Option B\n",
    "df_all_tasks = pd.read_csv('../ALP/alp481/all_tasks.csv').iloc[:,1:]\n",
    "df_all_tasks.replace({'A':1, 'B':2}, inplace=True)\n",
    "\n",
    "df_risk_task = pd.merge(left = df_risk_task, right = df_all_tasks, on = ['q_task','round1_choice','round2_choice','round3_choice'])\n",
    "df_risk_task['premium'] = df_risk_task['premium'].str.strip('%').astype(float) /100\n",
    "\n",
    "# Probability Weighting (PW) task: a7, a9, a11 (underweight), a8, a10, a12 (overweight)\n",
    "# Risk Aversion (RA) task: a2, a3, a4, a5\n",
    "df_inverseS_1 = df_risk_task[df_risk_task['q_task'].isin(['a7','a9','a11'])].groupby('prim_key')['premium'].sum()\n",
    "df_inverseS_2 = df_risk_task[df_risk_task['q_task'].isin(['a8','a10','a12'])].groupby('prim_key')['premium'].sum()\n",
    "df_inverseS_3 = df_risk_task[df_risk_task['q_task'].isin(['a2','a3','a4','a5'])].groupby('prim_key')['premium'].mean()\n",
    "\n",
    "df_inverseS_1 = df_inverseS_1.reset_index().rename(columns={'premium':'underweight'})\n",
    "df_inverseS_2 = df_inverseS_2.reset_index().rename(columns={'premium':'overweight'})\n",
    "df_inverseS_3 = df_inverseS_3.reset_index().rename(columns={'premium':'riskaversion'})\n",
    "\n",
    "df_inverseS = pd.merge(df_inverseS_1, df_inverseS_2, on='prim_key', how='inner')\n",
    "df_inverseS = pd.merge(df_inverseS, df_inverseS_3, on='prim_key', how='inner')\n",
    "\n",
    "df_inverseS['inverse_S'] = df_inverseS['underweight'] - df_inverseS['overweight']\n",
    "df_inverseS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants in the regression sample: 741\n"
     ]
    }
   ],
   "source": [
    "covariates = ['gender', #1 Male 2 Female\n",
    " 'calcage', #age\n",
    " 'currentlivingsituation', # 1 Married, 2 Separated, 3 Divorced, 4 Widowed, 5 Never married\n",
    " 'ethnicity', #1 White, 2 Black, 3 American Indian or Alaskan Native, 4 Asian or Pacific Islander, 5 Other\n",
    " 'hispaniclatino', #1 Yes, 2 No\n",
    " 'householdmembers',\n",
    " 'currentjobstatuss1', #1 Employed, NaN Other\n",
    " 'highesteducation', #1 Less than 1st grade, 2 1-4th grade, 3 5-6th grade, 4 7-8th grade, 5 9th grade, 6 10th grade, 7 11th grade, 8 12th grade NO DIPLOMA, 9 HIGH SCHOOL GRADUATE, 10 Some college but no degree, 11 Associate degree in college Occupational/vocational program, 12 Associate degree in college Academic program, 13 Bachelor's degree, 14 Master's degree, 15 Professional School Degree, 16 Doctorate degree\n",
    " 'familyincome', #1 Less than $5,000 2 $5,000 to $7,499 3 $7,500 to $9,999 4 $10,000 to $12,499 5 $12,500 to $14,999 6 $15,000 to $19,999 7 $20,000 to $24,999 8 $25,000 to $29,999 9 $30,000 to $34,999 10 $35,000 to $39,999 11 $40,000 to $49,999 12 $50,000 to $59,999 13 $60,000 to $74,999 14 $75,000 or more\n",
    " 'familyincome_part2', #1 $75,000-$99,999 2 $100,000-$124,999 3 $125,000-$199,999 4 $200,000 or more\n",
    " 'q19', #buy a lottery ticket, play at a casino, play a slot machine, or bet online in the last 3 months. 1 Yes, 2 No\n",
    " 'q20', #Financial Literacy (interest): correct = 1\n",
    " 'q21', #Financial Literacy (inflation): correct = 3\n",
    " 'q22', #Financial Literacy (diversification): correct = 2\n",
    " 'q23', #Numeracy (1): correct = 3\n",
    " 'q24', #Numeracy (2): correct = 2\n",
    " 'q25', #Numeracy (3): correct = 2\n",
    " 'q26', #Trust 0-5: 0 Most people can be trusted, 5 you can’t be too careful in dealing with people\n",
    " 'q27', #How long do you think you will live? Puri and Robinson (2007)\n",
    " ]\n",
    "\n",
    "# Merge stock holding data and risky choice data\n",
    "df_reg = pd.merge(left = df_raw[['prim_key','weight','ratio_indiv_stock','fin_wealth'] + covariates], \n",
    "                  right= df_inverseS,\n",
    "                  on='prim_key')\n",
    "\n",
    "df_reg = df_reg.rename(columns = {'calcage': 'age', 'q26':'trust'})\n",
    "\n",
    "# optimism: difference between self-reported and estimated life expectancy\n",
    "df_mortality = pd.read_csv('../ALP/alp481/mortality_table.csv')\n",
    "\n",
    "def life_expectancy(age,gender): \n",
    "\n",
    "    round_floor = np.floor(age / 5) * 5\n",
    "    round_ceil = np.ceil(age / 5) * 5\n",
    "\n",
    "    floor_diff = np.abs(age - round_floor)\n",
    "    ceil_diff = np.abs(age - round_ceil)\n",
    "\n",
    "    nearest = np.where(floor_diff <= ceil_diff, round_floor, round_ceil)\n",
    "\n",
    "    gender_encode = {1:'male',2:'female'}\n",
    "    gender_label = gender_encode.get(gender)\n",
    "\n",
    "    life_exp = df_mortality[df_mortality['age'] == nearest][gender_label] + nearest\n",
    "\n",
    "    return life_exp.values[0]\n",
    "\n",
    "df_reg['life_exp'] = df_reg.apply(lambda row: life_expectancy(row['age'], row['gender']), axis=1)\n",
    "df_reg['optimism'] = df_reg['q27'] - df_reg['life_exp']\n",
    "\n",
    "# gender, married, white, hispanic, employed, gambling, age\n",
    "df_reg['male'] = df_reg['gender'] == 1\n",
    "df_reg['married'] = df_reg['currentlivingsituation'] == 1\n",
    "df_reg['white'] = df_reg['ethnicity'] == 1\n",
    "df_reg['hispanic'] = df_reg['hispaniclatino'] == 1\n",
    "df_reg['employed'] = df_reg['currentjobstatuss1'] == 1\n",
    "df_reg['gambling'] = df_reg['q19'] == 1\n",
    "\n",
    "df_reg['age2'] = df_reg['age']**2\n",
    "df_reg['age_group'] = np.floor(df_reg['age'] / 10) * 10\n",
    "\n",
    "# education\n",
    "df_reg['no_college_degree'] = df_reg['highesteducation'] <= 10\n",
    "df_reg['bachelor_degree'] = df_reg['highesteducation'].between(11,13)\n",
    "df_reg['master_degree'] = df_reg['highesteducation'].between(14,16)\n",
    "\n",
    "# financial literacy & numeracy\n",
    "df_reg['fin_literacy'] = (df_reg['q20'] == 1) + (df_reg['q21'] == 3) + (df_reg['q22'] == 2)\n",
    "df_reg['numeracy'] = (df_reg['q23'] == 3) + (df_reg['q24'] == 2) + (df_reg['q25'] == 2)\n",
    "\n",
    "# family income & financial wealth\n",
    "df_reg['familyincome_rank'] = (df_reg['familyincome_part2'] - 1).fillna(0) + df_reg['familyincome'].fillna(0)\n",
    "\n",
    "income_lower = {1: 0, 2: 5000, 3: 7500, 4: 10000, 5: 12500, 6: 15000,\n",
    "                7: 20000, 8: 25000, 9: 30000, 10: 35000, 11: 40000, 12: 50000, 13: 60000,\n",
    "                14: 75000, 15: 100000, 16: 125000, 17: 200000}\n",
    "\n",
    "df_reg['familyincome_value'] = df_reg.apply(lambda row: income_lower.get(row['familyincome_rank']),axis=1) / 1e3\n",
    "df_reg['fin_wealth'] = df_reg['fin_wealth'] / 1e3\n",
    "\n",
    "df_reg = df_reg.astype({col: 'int' for col in df_reg.columns if df_reg[col].dtype == 'bool'})\n",
    "\n",
    "# Control variables\n",
    "exog_cols = [\n",
    "            'inverse_S','riskaversion',\n",
    "             'age','age2',\n",
    "             'age_group','male',\n",
    "             'married','white','hispanic','employed','householdmembers',\n",
    "             'no_college_degree','bachelor_degree','master_degree',\n",
    "             'familyincome_value',\n",
    "             'fin_wealth',\n",
    "             'fin_literacy','numeracy','trust',\n",
    "             'optimism',\n",
    "             'gambling'\n",
    "             ]\n",
    "\n",
    "# Some participants report \"don't know\" for q27 (optimism) and family income, which creates NAs.\n",
    "# Impute missing values with the group median \n",
    "df_reg['missing_value'] = df_reg.isna().any(axis=1).astype(int)\n",
    "\n",
    "demographic_group = ['age_group','male','no_college_degree','bachelor_degree','master_degree']\n",
    "\n",
    "impute_optimism = df_reg.groupby(demographic_group)['optimism'].median().reset_index()\n",
    "impute_familyincome = df_reg.groupby(demographic_group)['familyincome_value'].median().reset_index()\n",
    "\n",
    "df_reg = pd.merge(df_reg, impute_optimism, on=demographic_group, how='left', suffixes=('', '_imputed'))\n",
    "df_reg = pd.merge(df_reg, impute_familyincome, on=demographic_group, how='left', suffixes=('', '_imputed'))\n",
    "df_reg['optimism'] = df_reg['optimism'].fillna(df_reg['optimism_imputed'])\n",
    "df_reg['familyincome_value'] = df_reg['familyincome_value'].fillna(df_reg['familyincome_value_imputed'])\n",
    "\n",
    "exog_cols.remove('age_group')\n",
    "exog_cols = exog_cols + ['missing_value']\n",
    "\n",
    "# Only keep the individuals who hold equities \n",
    "df_reg = df_reg[~df_reg['ratio_indiv_stock'].isna()]\n",
    "df_reg = df_reg[['prim_key','weight','ratio_indiv_stock']+exog_cols]\n",
    "\n",
    "valid_prim_keys = df_reg['prim_key']\n",
    "print(\"Number of participants in the regression sample:\", len(valid_prim_keys))\n",
    "\n",
    "# Standardize all non-binary variables (except age)\n",
    "for var in ['inverse_S','riskaversion','householdmembers',\n",
    "             'familyincome_value','fin_wealth',\n",
    "             'fin_literacy','numeracy','trust','optimism']:\n",
    "    df_reg[var] = (df_reg[var] - df_reg[var].mean()) / df_reg[var].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>WLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>ratio_indiv_stock</td> <th>  R-squared:         </th> <td>   0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>WLS</td>        <th>  Adj. R-squared:    </th> <td>   0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   4.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 18 Jan 2025</td>  <th>  Prob (F-statistic):</th> <td>1.61e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:34:03</td>      <th>  Log-Likelihood:    </th> <td> -464.79</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   741</td>       <th>  AIC:               </th> <td>   971.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   720</td>       <th>  BIC:               </th> <td>   1068.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    20</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>    0.3198</td> <td>    0.125</td> <td>    2.565</td> <td> 0.011</td> <td>    0.075</td> <td>    0.565</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>inverse_S</th>          <td>    0.0078</td> <td>    0.015</td> <td>    0.529</td> <td> 0.597</td> <td>   -0.021</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>riskaversion</th>       <td>   -0.0032</td> <td>    0.015</td> <td>   -0.212</td> <td> 0.832</td> <td>   -0.033</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                <td>    0.0067</td> <td>    0.006</td> <td>    1.105</td> <td> 0.269</td> <td>   -0.005</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age2</th>               <td>-6.271e-05</td> <td> 5.91e-05</td> <td>   -1.061</td> <td> 0.289</td> <td>   -0.000</td> <td> 5.33e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>male</th>               <td>    0.0767</td> <td>    0.031</td> <td>    2.487</td> <td> 0.013</td> <td>    0.016</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>married</th>            <td>   -0.0359</td> <td>    0.036</td> <td>   -0.985</td> <td> 0.325</td> <td>   -0.107</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>white</th>              <td>   -0.1193</td> <td>    0.049</td> <td>   -2.456</td> <td> 0.014</td> <td>   -0.215</td> <td>   -0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hispanic</th>           <td>    0.0857</td> <td>    0.064</td> <td>    1.343</td> <td> 0.180</td> <td>   -0.040</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>employed</th>           <td>   -0.0358</td> <td>    0.045</td> <td>   -0.798</td> <td> 0.425</td> <td>   -0.124</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>householdmembers</th>   <td>   -0.0161</td> <td>    0.014</td> <td>   -1.110</td> <td> 0.267</td> <td>   -0.045</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_college_degree</th>  <td>    0.1594</td> <td>    0.048</td> <td>    3.347</td> <td> 0.001</td> <td>    0.066</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bachelor_degree</th>    <td>    0.1272</td> <td>    0.046</td> <td>    2.790</td> <td> 0.005</td> <td>    0.038</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>master_degree</th>      <td>    0.0332</td> <td>    0.048</td> <td>    0.688</td> <td> 0.492</td> <td>   -0.062</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>familyincome_value</th> <td>    0.0506</td> <td>    0.019</td> <td>    2.604</td> <td> 0.009</td> <td>    0.012</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fin_wealth</th>         <td>   -0.0335</td> <td>    0.008</td> <td>   -4.070</td> <td> 0.000</td> <td>   -0.050</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fin_literacy</th>       <td>   -0.0182</td> <td>    0.016</td> <td>   -1.150</td> <td> 0.250</td> <td>   -0.049</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numeracy</th>           <td>    0.0371</td> <td>    0.014</td> <td>    2.677</td> <td> 0.008</td> <td>    0.010</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>trust</th>              <td>    0.0269</td> <td>    0.015</td> <td>    1.789</td> <td> 0.074</td> <td>   -0.003</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>optimism</th>           <td>   -0.0467</td> <td>    0.011</td> <td>   -4.177</td> <td> 0.000</td> <td>   -0.069</td> <td>   -0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gambling</th>           <td>    0.0109</td> <td>    0.030</td> <td>    0.362</td> <td> 0.717</td> <td>   -0.048</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>missing_value</th>      <td>    0.0083</td> <td>    0.045</td> <td>    0.182</td> <td> 0.856</td> <td>   -0.081</td> <td>    0.097</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.863</td> <th>  Durbin-Watson:     </th> <td>   1.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.649</td> <th>  Jarque-Bera (JB):  </th> <td>   0.870</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.083</td> <th>  Prob(JB):          </th> <td>   0.647</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.974</td> <th>  Cond. No.          </th> <td>1.19e+19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.95e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}      & ratio\\_indiv\\_stock & \\textbf{  R-squared:         } &     0.107   \\\\\n",
       "\\textbf{Model:}              &         WLS         & \\textbf{  Adj. R-squared:    } &     0.082   \\\\\n",
       "\\textbf{Method:}             &    Least Squares    & \\textbf{  F-statistic:       } &     4.301   \\\\\n",
       "\\textbf{Date:}               &   Sat, 18 Jan 2025  & \\textbf{  Prob (F-statistic):} &  1.61e-09   \\\\\n",
       "\\textbf{Time:}               &       01:34:03      & \\textbf{  Log-Likelihood:    } &   -464.79   \\\\\n",
       "\\textbf{No. Observations:}   &           741       & \\textbf{  AIC:               } &     971.6   \\\\\n",
       "\\textbf{Df Residuals:}       &           720       & \\textbf{  BIC:               } &     1068.   \\\\\n",
       "\\textbf{Df Model:}           &            20       & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}    &      nonrobust      & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                             & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}               &       0.3198  &        0.125     &     2.565  &         0.011        &        0.075    &        0.565     \\\\\n",
       "\\textbf{inverse\\_S}          &       0.0078  &        0.015     &     0.529  &         0.597        &       -0.021    &        0.037     \\\\\n",
       "\\textbf{riskaversion}        &      -0.0032  &        0.015     &    -0.212  &         0.832        &       -0.033    &        0.026     \\\\\n",
       "\\textbf{age}                 &       0.0067  &        0.006     &     1.105  &         0.269        &       -0.005    &        0.019     \\\\\n",
       "\\textbf{age2}                &   -6.271e-05  &     5.91e-05     &    -1.061  &         0.289        &       -0.000    &     5.33e-05     \\\\\n",
       "\\textbf{male}                &       0.0767  &        0.031     &     2.487  &         0.013        &        0.016    &        0.137     \\\\\n",
       "\\textbf{married}             &      -0.0359  &        0.036     &    -0.985  &         0.325        &       -0.107    &        0.036     \\\\\n",
       "\\textbf{white}               &      -0.1193  &        0.049     &    -2.456  &         0.014        &       -0.215    &       -0.024     \\\\\n",
       "\\textbf{hispanic}            &       0.0857  &        0.064     &     1.343  &         0.180        &       -0.040    &        0.211     \\\\\n",
       "\\textbf{employed}            &      -0.0358  &        0.045     &    -0.798  &         0.425        &       -0.124    &        0.052     \\\\\n",
       "\\textbf{householdmembers}    &      -0.0161  &        0.014     &    -1.110  &         0.267        &       -0.045    &        0.012     \\\\\n",
       "\\textbf{no\\_college\\_degree} &       0.1594  &        0.048     &     3.347  &         0.001        &        0.066    &        0.253     \\\\\n",
       "\\textbf{bachelor\\_degree}    &       0.1272  &        0.046     &     2.790  &         0.005        &        0.038    &        0.217     \\\\\n",
       "\\textbf{master\\_degree}      &       0.0332  &        0.048     &     0.688  &         0.492        &       -0.062    &        0.128     \\\\\n",
       "\\textbf{familyincome\\_value} &       0.0506  &        0.019     &     2.604  &         0.009        &        0.012    &        0.089     \\\\\n",
       "\\textbf{fin\\_wealth}         &      -0.0335  &        0.008     &    -4.070  &         0.000        &       -0.050    &       -0.017     \\\\\n",
       "\\textbf{fin\\_literacy}       &      -0.0182  &        0.016     &    -1.150  &         0.250        &       -0.049    &        0.013     \\\\\n",
       "\\textbf{numeracy}            &       0.0371  &        0.014     &     2.677  &         0.008        &        0.010    &        0.064     \\\\\n",
       "\\textbf{trust}               &       0.0269  &        0.015     &     1.789  &         0.074        &       -0.003    &        0.056     \\\\\n",
       "\\textbf{optimism}            &      -0.0467  &        0.011     &    -4.177  &         0.000        &       -0.069    &       -0.025     \\\\\n",
       "\\textbf{gambling}            &       0.0109  &        0.030     &     0.362  &         0.717        &       -0.048    &        0.070     \\\\\n",
       "\\textbf{missing\\_value}      &       0.0083  &        0.045     &     0.182  &         0.856        &       -0.081    &        0.097     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.863 & \\textbf{  Durbin-Watson:     } &    1.963  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.649 & \\textbf{  Jarque-Bera (JB):  } &    0.870  \\\\\n",
       "\\textbf{Skew:}          & -0.083 & \\textbf{  Prob(JB):          } &    0.647  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.974 & \\textbf{  Cond. No.          } & 1.19e+19  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{WLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 4.95e-29. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            WLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:      ratio_indiv_stock   R-squared:                       0.107\n",
       "Model:                            WLS   Adj. R-squared:                  0.082\n",
       "Method:                 Least Squares   F-statistic:                     4.301\n",
       "Date:                Sat, 18 Jan 2025   Prob (F-statistic):           1.61e-09\n",
       "Time:                        01:34:03   Log-Likelihood:                -464.79\n",
       "No. Observations:                 741   AIC:                             971.6\n",
       "Df Residuals:                     720   BIC:                             1068.\n",
       "Df Model:                          20                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                  0.3198      0.125      2.565      0.011       0.075       0.565\n",
       "inverse_S              0.0078      0.015      0.529      0.597      -0.021       0.037\n",
       "riskaversion          -0.0032      0.015     -0.212      0.832      -0.033       0.026\n",
       "age                    0.0067      0.006      1.105      0.269      -0.005       0.019\n",
       "age2               -6.271e-05   5.91e-05     -1.061      0.289      -0.000    5.33e-05\n",
       "male                   0.0767      0.031      2.487      0.013       0.016       0.137\n",
       "married               -0.0359      0.036     -0.985      0.325      -0.107       0.036\n",
       "white                 -0.1193      0.049     -2.456      0.014      -0.215      -0.024\n",
       "hispanic               0.0857      0.064      1.343      0.180      -0.040       0.211\n",
       "employed              -0.0358      0.045     -0.798      0.425      -0.124       0.052\n",
       "householdmembers      -0.0161      0.014     -1.110      0.267      -0.045       0.012\n",
       "no_college_degree      0.1594      0.048      3.347      0.001       0.066       0.253\n",
       "bachelor_degree        0.1272      0.046      2.790      0.005       0.038       0.217\n",
       "master_degree          0.0332      0.048      0.688      0.492      -0.062       0.128\n",
       "familyincome_value     0.0506      0.019      2.604      0.009       0.012       0.089\n",
       "fin_wealth            -0.0335      0.008     -4.070      0.000      -0.050      -0.017\n",
       "fin_literacy          -0.0182      0.016     -1.150      0.250      -0.049       0.013\n",
       "numeracy               0.0371      0.014      2.677      0.008       0.010       0.064\n",
       "trust                  0.0269      0.015      1.789      0.074      -0.003       0.056\n",
       "optimism              -0.0467      0.011     -4.177      0.000      -0.069      -0.025\n",
       "gambling               0.0109      0.030      0.362      0.717      -0.048       0.070\n",
       "missing_value          0.0083      0.045      0.182      0.856      -0.081       0.097\n",
       "==============================================================================\n",
       "Omnibus:                        0.863   Durbin-Watson:                   1.963\n",
       "Prob(Omnibus):                  0.649   Jarque-Bera (JB):                0.870\n",
       "Skew:                          -0.083   Prob(JB):                        0.647\n",
       "Kurtosis:                       2.974   Cond. No.                     1.19e+19\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 4.95e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endog = df_reg['ratio_indiv_stock']\n",
    "exog = sm.add_constant(df_reg[exog_cols])\n",
    "\n",
    "reg_result = sm.WLS(endog, exog, weights=df_reg['weight']).fit()\n",
    "reg_result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax1.hist(df_reg['ratio_indiv_stock'],bins=30)\n",
    "ax1.set_xlabel('Fration of equity in individual stocks')\n",
    "\n",
    "ax2.hist(df_reg['inverse_S'],bins=30)\n",
    "ax2.set_xlabel('Inverse-S')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phd19zw1\\AppData\\Local\\Temp\\ipykernel_9828\\4011409852.py:21: RuntimeWarning: invalid value encountered in log\n",
      "  st.norm.logpdf((y - y_star) / sigma) - np.log(sigma)  # uncensored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: -60.3954, Degree of freedom: 21, p-value: 1.0000\n",
      "Pseudo R²: 0.0510\n",
      "              variable      coef          se         t         p\n",
      "0                const  0.322721   14.496817  0.022261  0.982246\n",
      "1            inverse_S  0.017591   18.570437  0.000947  0.999244\n",
      "2         riskaversion -0.013507  135.001507 -0.000100  0.999920\n",
      "3                  age  0.011070   88.823064  0.000125  0.999901\n",
      "4                 age2 -0.000105    1.416463 -0.000074  0.999941\n",
      "5                 male  0.142710  109.869066  0.001299  0.998964\n",
      "6              married -0.086825  258.561079 -0.000336  0.999732\n",
      "7                white -0.200257  309.269407 -0.000648  0.999484\n",
      "8             hispanic  0.159942  263.197676  0.000608  0.999515\n",
      "9             employed -0.068143   78.964815 -0.000863  0.999312\n",
      "10    householdmembers -0.039340  344.851640 -0.000114  0.999909\n",
      "11   no_college_degree  0.199287  257.543954  0.000774  0.999383\n",
      "12     bachelor_degree  0.166457   17.327532  0.009606  0.992338\n",
      "13       master_degree -0.043022  260.372414 -0.000165  0.999868\n",
      "14  familyincome_value  0.102842  421.882932  0.000244  0.999806\n",
      "15          fin_wealth -0.037486  428.543162 -0.000087  0.999930\n",
      "16        fin_literacy -0.039423  187.836147 -0.000210  0.999833\n",
      "17            numeracy  0.093277  109.380624  0.000853  0.999320\n",
      "18               trust  0.040167  317.344118  0.000127  0.999899\n",
      "19            optimism -0.116410  323.732823 -0.000360  0.999713\n",
      "20            gambling  0.009596   72.767190  0.000132  0.999895\n",
      "21       missing_value  0.009820   58.641740  0.000167  0.999866\n",
      "22               sigma  0.702040  137.381028  0.005110  0.995924\n"
     ]
    }
   ],
   "source": [
    "# Tobit model\n",
    "X = exog\n",
    "y = endog\n",
    "weights = df_reg['weight']\n",
    "reg_var_names = reg_result.params.index\n",
    "init_beta = reg_result.params.values\n",
    "init_sigma = 1.0\n",
    "\n",
    "# Weighted Tobit log-likelihood\n",
    "def weighted_tobit_loglike(params, X, y, weights):\n",
    "    beta = params[:-1]  \n",
    "    sigma = params[-1]  \n",
    "    y_star = X @ beta \n",
    "\n",
    "    ll = np.where(\n",
    "        y == 0,\n",
    "        st.norm.logcdf(- y_star / sigma),  # left-truncated\n",
    "        np.where(\n",
    "            y == 1,\n",
    "            st.norm.logcdf((y_star - 1) / sigma),  # right-truncated\n",
    "            st.norm.logpdf((y - y_star) / sigma) - np.log(sigma)  # uncensored\n",
    "        )\n",
    "    )\n",
    "    return -np.sum(weights * ll)  # objective\n",
    "\n",
    "# Initial parameters (beta, sigma)\n",
    "initial_params = np.append(init_beta, init_sigma)\n",
    "\n",
    "# Optimization\n",
    "tobit_result = optimize.minimize(weighted_tobit_loglike, initial_params, \n",
    "                           args=(X, y, weights), \n",
    "                           method='L-BFGS-B')\n",
    "\n",
    "# F-test\n",
    "# Restricted model\n",
    "X_restricted = np.ones((len(y), 1))  # Only intercept\n",
    "init_params_restricted = np.append(init_beta[0], init_sigma)  # (intercept, sigma)\n",
    "\n",
    "result_restricted = optimize.minimize(weighted_tobit_loglike, init_params_restricted, \n",
    "                             args=(X_restricted, y, weights), \n",
    "                             method='L-BFGS-B')\n",
    "\n",
    "# Calculate LR statistics\n",
    "LR = -2 * (result_restricted.fun - tobit_result.fun)\n",
    "diff_dof = exog.shape[1] - X_restricted.shape[1] # difference in degree of freedom\n",
    "\n",
    "p_value_f = st.chi2.sf(LR, diff_dof)\n",
    "print(f\"LR: {LR:.4f}, Degree of freedom: {diff_dof}, p-value: {p_value_f:.4f}\")\n",
    "\n",
    "#Pseudo R²\n",
    "pseudo_r2 = 1 - (tobit_result.fun / result_restricted.fun)\n",
    "print(f\"Pseudo R²: {pseudo_r2:.4f}\")\n",
    "\n",
    "# t-tests\n",
    "# Hessian matrix\n",
    "hessian_inv = tobit_result.hess_inv.todense() \n",
    "standard_errors = np.sqrt(np.diag(hessian_inv))\n",
    "t_values = tobit_result.x / standard_errors\n",
    "p_values = [2 * (1 - st.t.cdf(np.abs(t), df=(len(y) - exog.shape[1] - 1))) for t in t_values]\n",
    "\n",
    "# write the t-test results\n",
    "t_test_result = {'variable':np.append(reg_var_names,'sigma'),\n",
    "                 'coef': tobit_result.x,\n",
    "                 'se': standard_errors,\n",
    "                 't': t_values,\n",
    "                 'p': p_values}\n",
    "\n",
    "print(pd.DataFrame(t_test_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants for model estimation: 737\n"
     ]
    }
   ],
   "source": [
    "# RA tasks\n",
    "# Option A: win $[a_amount_1] with 33% chance, or else $[a_amount_2] with 67% chance.\n",
    "# Option B: win $X with 33% chance \n",
    "ra_prob_a = [np.array([0.33,0.67])]*4\n",
    "ra_prob_b = [0.33]*4\n",
    "ra_amount_a = [np.array(a) for a in [[12,3],[18,3],[24,3],[30,3]]]\n",
    "\n",
    "# PW tasks\n",
    "# Option A: win $42 with [a_prob] chance, or else $6 with [1-a_prob] chance.\n",
    "# Option B: win $X for sure\n",
    "pw_prob_a = [np.array([p,1-p]) for p in [0.5,0.25,0.75,0.12,0.88,0.05]]\n",
    "pw_prob_b = [1]*6\n",
    "pw_amount_a = [np.array([42,6])]*6\n",
    "\n",
    "task_list = ['a2','a3','a4','a5','a7', 'a8', 'a9', 'a10', 'a11', 'a12']\n",
    "\n",
    "task_setup = {'q_task': task_list,\n",
    "              'prob_a': ra_prob_a + pw_prob_a,\n",
    "              'prob_b': ra_prob_b + pw_prob_b,\n",
    "              'amount_a': ra_amount_a + pw_amount_a}\n",
    "\n",
    "# Create variables for these attributes\n",
    "df_risk = pd.merge(left = df_risk_task,\n",
    "                    right = pd.DataFrame(task_setup),\n",
    "                    on = 'q_task')\n",
    "\n",
    "for var in ['prob_a','prob_b','amount_a']:\n",
    "    df_risk[f'round1_{var}'] = df_risk[var]\n",
    "    df_risk[f'round2_{var}'] = df_risk[var]\n",
    "    df_risk[f'round3_{var}'] = df_risk[var]\n",
    "\n",
    "# Each row represents an individual\n",
    "df_risk = df_risk.pivot_table(index = 'prim_key',\n",
    "                    columns = 'q_task',\n",
    "                    values = [col for col in df_risk.columns if 'round' in col],\n",
    "                    aggfunc='first')\n",
    "\n",
    "df_risk.columns = [f'{task}_{col}' for col, task in df_risk.columns]\n",
    "df_risk = df_risk[sorted(df_risk.columns)][[col for col in df_risk.columns if 'round' in col]].reset_index()\n",
    "\n",
    "# Relabel: 1 = choosing option A, 0 = choosing option B\n",
    "choice_cols = [col for col in df_risk.columns if 'choice' in col]\n",
    "df_risk[choice_cols] = 2 - df_risk[choice_cols]\n",
    "\n",
    "df_equity = pd.merge(left = df_reg[['prim_key','weight']],right = df_risk,on='prim_key').dropna()\n",
    "print('Number of participants for model estimation:',len(df_equity))\n",
    "\n",
    "# Specify x1, x2, p1, p2\n",
    "p_a = [col for col in df_equity.columns if 'prob_a' in col]\n",
    "p_b = [col for col in df_equity.columns if 'prob_b' in col]\n",
    "x_a = [col for col in df_equity.columns if 'amount_a' in col]\n",
    "x_b = [col for col in df_equity.columns if 'x' in col]\n",
    "\n",
    "# df_risk[x_b].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 11415351.137729723\n",
       "        x: [ 3.364e-01  1.737e-01  1.380e+00]\n",
       "      nit: 11\n",
       "      jac: [ 5.029e+00 -1.118e+00 -1.118e+00]\n",
       "     nfev: 48\n",
       "     njev: 12\n",
       " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = [(0,1),(0,1),(0,None)]\n",
    "\n",
    "model = DCM.mixedDiscrete(data=df_equity,\n",
    "                choice = choice_cols,\n",
    "                x1 = x_a,\n",
    "                x2 = x_b,\n",
    "                p1 = p_a,\n",
    "                p2 = p_b)\n",
    "\n",
    "model.set_init_param(param_keys=['riskCoef','probW','temp'],\n",
    "                     param_init=[0.5,0.5,1],\n",
    "                     weight = df_equity['weight'].values)\n",
    "\n",
    "model.fit_param(bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(10375.274925564987)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DCM.get_best_result(model,bounds,n_class=2,n_init_point=8,name_prefix='models_prob_weigh/pw',name_suffix='2param')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(10181.15292759154)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DCM.get_best_result(model,bounds,n_class=3,n_init_point=8,name_prefix='models_prob_weigh/pw',name_suffix='2param')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(10389.910145739797)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DCM.get_best_result(model,bounds,n_class=4,n_init_point=8,name_prefix='models_prob_weigh/pw',name_suffix='2param')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(9891.13953999787)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DCM.get_best_result(model,bounds,n_class=5,n_init_point=8,name_prefix='models_prob_weigh/pw',name_suffix='2param')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 11415351.156314367\n",
       "        x: [ 3.365e-01  1.737e-01]\n",
       "      nit: 7\n",
       "      jac: [-1.863e-01  0.000e+00]\n",
       "     nfev: 30\n",
       "     njev: 10\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = [(0,1),(0,1)]\n",
    "\n",
    "model = DCM.mixedDiscrete(data=df_equity,\n",
    "                choice = choice_cols,\n",
    "                x1 = x_a,\n",
    "                x2 = x_b,\n",
    "                p1 = p_a,\n",
    "                p2 = p_b,\n",
    "                fixed_args ={'temp': 1.38})\n",
    "\n",
    "model.set_init_param(param_keys=['riskCoef','probW'],\n",
    "                     param_init=[0.5,0.5],\n",
    "                     weight = df_equity['weight'].values)\n",
    "\n",
    "model.fit_param(bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching optimal value for temp\n",
      "Step 1: 0.7333333333333333\n",
      "Evaluation metrics: 11026.202998691657, 11211.180491725672\n",
      "Step 2: 0.9111111111111111\n",
      "Evaluation metrics: 11089.87984064133, 11040.626130675402\n",
      "Step 3: 0.7925925925925926\n",
      "Evaluation metrics: 11025.96713583033, 11057.002501251263\n",
      "Step 4: 0.8716049382716049\n",
      "Evaluation metrics: 11227.023337399845, 11033.809159805196\n",
      "Step 5: 0.8189300411522633\n",
      "Evaluation metrics: 11027.581486486903, 11197.328761860785\n",
      "Step 6: 0.7838134430727024\n",
      "Evaluation metrics: 11025.637205809016, 11030.980989741725\n",
      "Step 7: 0.7604023776863282\n",
      "Evaluation metrics: 11025.335194286426, 11205.937038661028\n",
      "Step 8: 0.7447950007620789\n",
      "Evaluation metrics: 11025.661016340375, 11208.306761322268\n",
      "Step 9: 0.7551999187115785\n",
      "Evaluation metrics: 11026.141847087521, 11025.393367868895\n",
      "Step 10: 0.7482633067452454\n",
      "Evaluation metrics: 11025.5509568436, 11213.953004860661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'temp': 0.7482633067452454}, np.float64(11025.550055084097))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DCM.bisection_search(model, bounds, arg_name = 'temp', arg_range = [0.2, 1.8],\n",
    "                     n_class=2, n_init_point = 8, name_prefix = 'models_prob_weigh/pw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching optimal value for temp\n",
      "Step 1: 1.2666666666666666\n",
      "Evaluation metrics: 11070.746372845992, 10935.416696551916\n",
      "Step 2: 1.4444444444444446\n",
      "Evaluation metrics: 10986.475689008812, 10968.276086196913\n",
      "Step 3: 1.5629629629629629\n",
      "Evaluation metrics: 11036.527068931988, 10990.6782196161\n",
      "Step 4: 1.4839506172839507\n",
      "Evaluation metrics: 11049.381121157723, 11063.790841445829\n",
      "Step 5: 1.4312757201646091\n",
      "Evaluation metrics: 10965.791677210396, 10985.706400635521\n",
      "Step 6: 1.396159122085048\n",
      "Evaluation metrics: 10959.187829935643, 10972.422889260843\n",
      "Step 7: 1.3727480566986738\n",
      "Evaluation metrics: 10954.809619489477, 10963.58644017959\n",
      "Step 8: 1.3571406797744245\n",
      "Evaluation metrics: 10951.905219091776, 10957.725948237317\n",
      "Step 9: 1.3467357618249252\n",
      "Evaluation metrics: 10949.976589793976, 10953.840145323014\n",
      "Step 10: 1.339799149858592\n",
      "Evaluation metrics: 10948.694537954772, 10951.261601137514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'temp': 1.339799149858592}, np.float64(10948.69447434905))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DCM.bisection_search(model, bounds, arg_name = 'temp', arg_range = [0.2, 1.8],\n",
    "                     n_class=3, n_init_point = 8, name_prefix = 'models_prob_weigh/pw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching optimal value for temp\n",
      "Step 1: 1.2666666666666666\n",
      "Evaluation metrics: 10867.120170438462, 10764.975883097179\n",
      "Step 2: 1.088888888888889\n",
      "Evaluation metrics: 10886.161855257136, 10968.154542487657\n",
      "Step 3: 1.2074074074074075\n",
      "Evaluation metrics: 10809.083962240924, 10754.958677536813\n",
      "Step 4: 1.2864197530864199\n",
      "Evaluation metrics: 10896.886714541266, 10768.460055855478\n",
      "Step 5: 1.3390946502057615\n",
      "Evaluation metrics: 10836.671321589329, 10777.822042109387\n",
      "Step 6: 1.3039780521262003\n",
      "Evaluation metrics: 10937.674557036129, 10953.666693307805\n",
      "Step 7: 1.3273891175125745\n",
      "Evaluation metrics: 10932.433759181487, 10775.72017596186\n",
      "Step 8: 1.3117817405883252\n",
      "Evaluation metrics: 10772.937440332184, 10778.478303104555\n",
      "Step 9: 1.3221866585378246\n",
      "Evaluation metrics: 10845.119976685455, 10774.746412570626\n",
      "Step 10: 1.3152500465714918\n",
      "Evaluation metrics: 10773.506811657762, 10776.031700758891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'temp': 1.3152500465714918}, np.float64(10773.50208654423))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DCM.bisection_search(model, bounds, arg_name = 'temp', arg_range = [0.2, 1.8],\n",
    "                     n_class=4, n_init_point = 8, name_prefix = 'models_prob_weigh/pw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching optimal value for temp\n",
      "Step 1: 1.2666666666666666\n",
      "Evaluation metrics: 10916.814080193244, 10764.864333768555\n",
      "Step 2: 1.088888888888889\n",
      "Evaluation metrics: 10667.605143585457, 10796.984415066063\n",
      "Step 3: 0.9703703703703704\n",
      "Evaluation metrics: 10705.753844310999, 10728.478439200826\n",
      "Step 4: 1.0493827160493827\n",
      "Evaluation metrics: 10692.990469866887, 10684.357932243774\n",
      "Step 5: 1.1020576131687243\n",
      "Evaluation metrics: 10866.186766997906, 10731.482951333946\n",
      "Step 6: 1.0669410150891634\n",
      "Evaluation metrics: 10724.285110202443, 10738.825096343586\n",
      "Step 7: 1.0435299497027892\n",
      "Evaluation metrics: 10719.594982944956, 10729.064748228628\n",
      "Step 8: 1.02792257277854\n",
      "Evaluation metrics: 10678.510331514772, 10732.353774357092\n",
      "Step 9: 1.0175176548290403\n",
      "Evaluation metrics: 10714.514900422708, 10718.566550124884\n",
      "Step 10: 1.0105810428627073\n",
      "Evaluation metrics: 10713.184490914018, 10715.853124286607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'temp': 1.0105810428627073}, np.float64(10713.184435777392))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DCM.bisection_search(model, bounds, arg_name = 'temp', arg_range = [0.2, 1.8],\n",
    "                     n_class=5, n_init_point = 8, name_prefix = 'models_prob_weigh/pw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: 2 , p-value: 1.3779862742313282e-27\n",
      "task: 3 , p-value: 6.153031092758909e-26\n",
      "task: 4 , p-value: 1.1248669398773394e-21\n",
      "task: 5 , p-value: 6.024142679574086e-23\n",
      "task: 7 , p-value: 3.3769125805714923e-16\n",
      "task: 8 , p-value: 2.347640357107383e-36\n",
      "task: 9 , p-value: 3.082748063589614e-18\n",
      "task: 10 , p-value: 1.2509563626555807e-22\n",
      "task: 11 , p-value: 9.702562228849847e-07\n",
      "task: 12 , p-value: 1.0343681241541295e-34\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df_raw[['prim_key']+q_risk_vars].melt(id_vars = 'prim_key',\n",
    "                                      var_name = 'q_risk',\n",
    "                                      value_name = 'choice',\n",
    "                                      value_vars = q_risk_vars).dropna()\n",
    "\n",
    "df_filtered = df_filtered[df_filtered['q_risk'].str.split('_').str[1].eq('3')]\n",
    "df_filtered = df_filtered[df_filtered['prim_key'].isin(valid_prim_keys)]\n",
    "\n",
    "df_filtered['task'] = df_filtered['q_risk'].str.extract(r'a(\\d+)').astype(int)\n",
    "df_filtered['round3'] = df_filtered['q_risk'].str.split('_').str[2].astype(int)\n",
    "df_filtered['rank'] = (df_filtered['round3'] - 4)*2 + (3 - df_filtered['choice'])\n",
    "tab_count_all = df_filtered[['prim_key','task','rank']].dropna().groupby(['task','rank']).count().reset_index()\n",
    "\n",
    "task_list = tab_count_all['task'].unique()\n",
    "\n",
    "for i in range(len(task_list)):\n",
    "    tab_count = tab_count_all[tab_count_all['task'] == task_list[i]].sort_values('rank')\n",
    "    tab_count = tab_count[['rank','prim_key']].set_index('rank')['prim_key']\n",
    "    tab_count.index = tab_count.index.astype(int).astype(str)\n",
    "\n",
    "    result_prop_test = DCM.prop_test(tab_count,hide=True)\n",
    "    prop_test_sort = sorted(result_prop_test[['p_lo_hi']].values.flatten(),reverse= True)\n",
    "    \n",
    "    print('task:',task_list[i],', p-value:',min(np.array(prop_test_sort) * np.arange(1,len(prop_test_sort)+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phd19zw1\\OneDrive - University of Warwick\\preference_reanalysis\\staircase\\DCM.py:584: RuntimeWarning: divide by zero encountered in log\n",
      "  self.obj_func = - np.sum(self.w * np.log(self.likeIndiv(const))) / self.n_random\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "{'mean': [np.float64(-0.06133165555125591), np.float64(0.005372173717367307), np.float64(0.06953644158821008)], 'variance': array([[1.0929417 , 0.18131064, 0.44668446],\n",
      "       [0.18131064, 0.9525198 , 0.15870932],\n",
      "       [0.44668446, 0.15870932, 1.11783085]])}\n",
      "gradient: (array([ 16.68627154,  -1.29494186, -17.02832158]), array([[ 94.22177748, -11.94410338, -35.95513821],\n",
      "       [-11.94410338,  92.64739896,  -8.38119716],\n",
      "       [-35.95513821,  -8.38119716,  91.3765177 ]]))\n",
      "objective: inf\n",
      "Iteration 2\n",
      "{'mean': [np.float64(-0.08902370908749037), np.float64(-0.06781395134345967), np.float64(0.022015995445825325)], 'variance': array([[1.44274799, 0.28600306, 0.69982399],\n",
      "       [0.28600306, 0.85933534, 0.15864289],\n",
      "       [0.69982399, 0.15864289, 1.16866292]])}\n",
      "gradient: (array([ 14.88434082,  10.93155107, -13.59028523]), array([[ 86.47083074, -19.71384354, -49.10475015],\n",
      "       [-19.71384354, 105.65544945,  -2.53731433],\n",
      "       [-49.10475015,  -2.53731433, 102.27065662]]))\n",
      "objective: inf\n",
      "Iteration 3\n",
      "{'mean': [np.float64(-0.1304956480032099), np.float64(-0.111491793791355), np.float64(-0.013929833500677207)], 'variance': array([[1.9921927 , 0.30549182, 0.87077568],\n",
      "       [0.30549182, 0.75339907, 0.09481205],\n",
      "       [0.87077568, 0.09481205, 1.09416286]])}\n",
      "gradient: (array([11.78148352, 21.44933362, -9.07680429]), array([[ 69.00647887, -21.3021837 , -53.0720445 ],\n",
      "       [-21.3021837 , 120.30998911,   6.52790133],\n",
      "       [-53.0720445 ,   6.52790133, 119.13001412]]))\n",
      "objective: inf\n",
      "Iteration 4\n",
      "{'mean': [np.float64(-0.18828787084590487), np.float64(-0.1286866880569522), np.float64(-0.03699245232003542)], 'variance': array([[2.47099066, 0.24968108, 0.88995461],\n",
      "       [0.24968108, 0.71205295, 0.0178875 ],\n",
      "       [0.88995461, 0.0178875 , 0.98755544]])}\n",
      "gradient: (array([12.02263039, 26.54310209, -4.96576023]), array([[ 53.22508746, -17.46637781, -47.64844647],\n",
      "       [-17.46637781, 124.81182131,  13.4794583 ],\n",
      "       [-47.64844647,  13.4794583 , 128.51588026]]))\n",
      "objective: inf\n",
      "Iteration 5\n",
      "{'mean': [np.float64(-0.2755079115840589), np.float64(-0.13734954190121992), np.float64(-0.05456870034659435)], 'variance': array([[ 2.69282153,  0.16943407,  0.83752397],\n",
      "       [ 0.16943407,  0.67249049, -0.03599023],\n",
      "       [ 0.83752397, -0.03599023,  0.92358177]])}\n",
      "gradient: (array([16.65880246, 30.21314381, -3.91419309]), array([[ 45.26200856, -13.62880793, -41.57565934],\n",
      "       [-13.62880793, 130.39526376,  17.44015463],\n",
      "       [-41.57565934,  17.44015463, 130.14657191]]))\n",
      "objective: inf\n",
      "Iteration 6\n",
      "{'mean': [np.float64(-0.34033810635289363), np.float64(-0.1366692752220632), np.float64(-0.06683398738921476)], 'variance': array([[ 2.78947355,  0.1147809 ,  0.76770325],\n",
      "       [ 0.1147809 ,  0.65710836, -0.07612444],\n",
      "       [ 0.76770325, -0.07612444,  0.89668506]])}\n",
      "gradient: (array([19.84064407, 31.59555002, -1.6703853 ]), array([[ 40.69900951, -11.25651834, -35.80037169],\n",
      "       [-11.25651834, 133.37270935,  20.96007854],\n",
      "       [-35.80037169,  20.96007854, 126.94797432]]))\n",
      "objective: inf\n",
      "Iteration 7\n",
      "{'mean': [np.float64(-0.3700404549789545), np.float64(-0.14824661585079557), np.float64(-0.06748046537641542)], 'variance': array([[ 2.68536652,  0.07477515,  0.68871878],\n",
      "       [ 0.07477515,  0.65510996, -0.10292448],\n",
      "       [ 0.68871878, -0.10292448,  0.91022982]])}\n",
      "gradient: (array([22.46247393, 35.73280345, -0.38917872]), array([[ 39.82668437,  -9.4481717 , -31.20292587],\n",
      "       [ -9.4481717 , 133.95304434,  22.29566686],\n",
      "       [-31.20292587,  22.29566686, 119.24189198]]))\n",
      "objective: inf\n",
      "Iteration 8\n",
      "{'mean': [np.float64(-0.4056923454352637), np.float64(-0.16413673183744146), np.float64(-0.06473304751116293)], 'variance': array([[ 2.62757217,  0.03334872,  0.71447179],\n",
      "       [ 0.03334872,  0.6448904 , -0.11950492],\n",
      "       [ 0.71447179, -0.11950492,  0.96429294]])}\n",
      "gradient: (array([26.50689706, 41.18665047, -3.15652994]), array([[ 40.85218651,  -7.90313305, -31.24797116],\n",
      "       [ -7.90313305, 136.03992366,  22.71509539],\n",
      "       [-31.24797116,  22.71509539, 113.85863179]]))\n",
      "objective: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phd19zw1\\OneDrive - University of Warwick\\preference_reanalysis\\staircase\\DCM.py:584: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.obj_func = - np.sum(self.w * np.log(self.likeIndiv(const))) / self.n_random\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9\n",
      "{'mean': [np.float64(-0.4058567087186077), np.float64(-0.16813548937893055), np.float64(-0.06264658681607392)], 'variance': array([[ 2.60344537,  0.0042986 ,  0.73060855],\n",
      "       [ 0.0042986 ,  0.6416774 , -0.13544166],\n",
      "       [ 0.73060855, -0.13544166,  0.98742088]])}\n",
      "gradient: (array([27.33702245, 43.4912153 , -3.50732219]), array([[ 41.43726559,  -6.95038013, -31.61346123],\n",
      "       [ -6.95038013, 137.18380485,  23.95980322],\n",
      "       [-31.61346123,  23.95980322, 112.51021563]]))\n",
      "objective: nan\n",
      "Iteration 10\n",
      "{'mean': [np.float64(-0.40892630520926415), np.float64(-0.17901444372527897), np.float64(-0.04707666077814151)], 'variance': array([[ 2.51776537, -0.05453586,  0.75032779],\n",
      "       [-0.05453586,  0.60874342, -0.13458213],\n",
      "       [ 0.75032779, -0.13458213,  0.9910637 ]])}\n",
      "gradient: (array([31.22121149, 50.72087889, -8.69799707]), array([[ 43.55452364,  -3.49306299, -33.44918531],\n",
      "       [ -3.49306299, 143.81501898,  22.17402739],\n",
      "       [-33.44918531,  22.17402739, 113.85221378]]))\n",
      "objective: nan\n"
     ]
    }
   ],
   "source": [
    "model = DCM.mixedNormal(data=df_equity,\n",
    "                choice = choice_cols,\n",
    "                x1 = x_a,\n",
    "                x2 = x_b,\n",
    "                p1 = p_a,\n",
    "                p2 = p_b)\n",
    "\n",
    "model.set_init_mixed(meta_param = {'mean':[0.1,0.1,0.1],'variance':[[1,0.1,0.1],[0.1,1,0.1],[0.1,0.1,1]]}, \n",
    "                     param_keys= ['riskCoef','probW','temp'],\n",
    "                     dist_type=['johnson_sb','johnson_sb','lognormal'],\n",
    "                     n_draws = 100,\n",
    "                     n_batch = 10,\n",
    "                     weight = df_equity['weight'].values)\n",
    "\n",
    "model.runEM(max_iter=100,min_iter=10,excess_step=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'riskCoef': array([0.41001835, 0.40050051, 0.42206282, 0.45650133, 0.43669154,\n",
       "        0.41945631, 0.42433435, 0.45974171, 0.42407846, 0.4607662 ,\n",
       "        0.50602017, 0.40386978, 0.42596851, 0.42347258, 0.41085799,\n",
       "        0.44608355, 0.40109496, 0.42192711, 0.43285625, 0.42830507,\n",
       "        0.42882449, 0.38398995, 0.71703913, 0.45785627, 0.45312306,\n",
       "        0.20069444, 0.38893318, 0.4148472 , 0.4218661 , 0.41881578,\n",
       "        0.42670191, 0.43493592, 0.41693226, 0.39921576, 0.42992049,\n",
       "        0.46448025, 0.45951073, 0.43143221, 0.2548122 , 0.44081362,\n",
       "        0.44906608, 0.49162741, 0.41550275, 0.43245438, 0.44855114,\n",
       "        0.50816165, 0.41945638, 0.41985082, 0.34406744, 0.43020942,\n",
       "        0.44594319, 0.35202685, 0.44085683, 0.47785002, 0.39704256,\n",
       "        0.44325985, 0.55674183, 0.4111372 , 0.425309  , 0.378899  ,\n",
       "        0.46406199, 0.44755047, 0.44080425, 0.45350096, 0.42719446,\n",
       "        0.43131963, 0.41907598, 0.45854083, 0.43575544, 0.41987901,\n",
       "        0.39399054, 0.43084723, 0.46799885, 0.42922784, 0.43329939,\n",
       "        0.44256362, 0.44289112, 0.43249619, 0.42816867, 0.4571282 ,\n",
       "        0.49541442, 0.42997179, 0.4251862 , 0.42062326, 0.439722  ,\n",
       "        0.48170932, 0.43147909, 0.39581497, 0.43222985, 0.41633576,\n",
       "        0.42616806, 0.42542528, 0.2297122 , 0.42882532, 0.40054585,\n",
       "        0.4107278 , 0.44074754, 0.44292009, 0.38797149, 0.47479663,\n",
       "        0.44699307, 0.4800433 , 0.41606506, 0.44585728, 0.44266615,\n",
       "        0.43936707, 0.42714731, 0.4299983 , 0.42066806, 0.41598084,\n",
       "        0.36709695, 0.41959998, 0.43669182, 0.43888539, 0.45962915,\n",
       "        0.48136535, 0.54598333, 0.3984863 , 0.41654208, 0.45440137,\n",
       "        0.40692106, 0.45478082, 0.41438498, 0.46107797, 0.44085217,\n",
       "        0.42016417, 0.41561744, 0.44110755, 0.44043877, 0.50563141,\n",
       "        0.4263082 , 0.41653102, 0.43059307, 0.44855794, 0.45525537,\n",
       "        0.43714638, 0.52381831, 0.4155847 , 0.42954213, 0.4144867 ,\n",
       "        0.56794614, 0.45301135, 0.23645279, 0.42130954, 0.46962178,\n",
       "        0.41667219, 0.43118048, 0.43513789, 0.41875785, 0.44690458,\n",
       "        0.38598888, 0.44025553, 0.44116323, 0.58146325, 0.42452147,\n",
       "        0.43947597, 0.45020286, 0.44146107, 0.45665944, 0.42764731,\n",
       "        0.47258638, 0.43462145, 0.36682782, 0.396919  , 0.46981322,\n",
       "        0.40147945, 0.42214564, 0.42192844, 0.44180177, 0.42122857,\n",
       "        0.46224949, 0.44467719, 0.44982455, 0.43584504, 0.44026706,\n",
       "        0.43171836, 0.46948974, 0.4459771 , 0.4773598 , 0.43469275,\n",
       "        0.44806725, 0.43684447, 0.45017473, 0.46748007, 0.411763  ,\n",
       "        0.42863707, 0.4724614 , 0.44047285, 0.40605913, 0.30536432,\n",
       "        0.4240369 , 0.43598785, 0.47458722, 0.45213724, 0.41624097,\n",
       "        0.58104634, 0.49566371, 0.44411831, 0.35918853, 0.44049624,\n",
       "        0.30321158, 0.44632786, 0.40433632, 0.50148476, 0.45256553,\n",
       "        0.46366204, 0.47315428, 0.43881537, 0.40153018, 0.43206932,\n",
       "        0.43971417, 0.47640353, 0.43285746, 0.42565041, 0.4444268 ,\n",
       "        0.38420408, 0.45258087, 0.41179244, 0.41731669, 0.49130115,\n",
       "        0.42257398, 0.44805912, 0.43681215, 0.43651358, 0.41061968,\n",
       "        0.43031479, 0.44011095, 0.41636568, 0.41970459, 0.44600524,\n",
       "        0.47529506, 0.44960974, 0.45509845, 0.43114709, 0.42959657,\n",
       "        0.46603011, 0.49400219, 0.4089458 , 0.41465889, 0.37588383,\n",
       "        0.45900459, 0.43574593, 0.42982937, 0.42757801, 0.40570392,\n",
       "        0.38883185, 0.46886082, 0.3880011 , 0.43480051, 0.45222708,\n",
       "        0.44007958, 0.43290003, 0.42995968, 0.40953747, 0.6651991 ,\n",
       "        0.25288595, 0.46579161, 0.40776893, 0.44604243, 0.44396167,\n",
       "        0.40124785, 0.39903364, 0.37414561, 0.5078379 , 0.59724213,\n",
       "        0.40958587, 0.35337903, 0.40035031, 0.44545977, 0.49049978,\n",
       "        0.41109516, 0.46329197, 0.46295863, 0.43735889, 0.45028497,\n",
       "        0.36886987, 0.41844693, 0.48960502, 0.45437006, 0.45506245,\n",
       "        0.42896585, 0.46703568, 0.43589208, 0.46291592, 0.43033924,\n",
       "        0.41441106, 0.38075525, 0.45909727, 0.41844159, 0.45343235,\n",
       "        0.42964815, 0.5078683 , 0.43537585, 0.43747219, 0.41165059,\n",
       "        0.41669635, 0.41603202, 0.45206561, 0.46256914, 0.40270154,\n",
       "        0.44966713, 0.47242727, 0.43894952, 0.39264515, 0.46521554,\n",
       "        0.42433424, 0.40082113, 0.4525977 , 0.40648735, 0.43120899,\n",
       "        0.45461041, 0.47900348, 0.45008919, 0.40143347, 0.51143389,\n",
       "        0.45152856, 0.41648615, 0.44367249, 0.4476295 , 0.40011436,\n",
       "        0.38990204, 0.33141925, 0.41474827, 0.46767285, 0.42587161,\n",
       "        0.43768257, 0.42441116, 0.50247559, 0.41904576, 0.53179379,\n",
       "        0.4189735 , 0.4317645 , 0.47294328, 0.46128321, 0.43266516,\n",
       "        0.45038816, 0.40634223, 0.45837049, 0.44325937, 0.43605758,\n",
       "        0.42959327, 0.43393866, 0.50503854, 0.45264893, 0.41669154,\n",
       "        0.41906373, 0.38222685, 0.44645612, 0.54499353, 0.44312208,\n",
       "        0.4344034 , 0.43242901, 0.46673907, 0.42356193, 0.15515893,\n",
       "        0.43402732, 0.42811043, 0.43114533, 0.44211758, 0.45242357,\n",
       "        0.43380988, 0.41082644, 0.43961881, 0.5954688 , 0.43233136,\n",
       "        0.37008854, 0.42062147, 0.41019558, 0.45595735, 0.48476495,\n",
       "        0.44852124, 0.3917468 , 0.45212042, 0.42239302, 0.46785586,\n",
       "        0.43582937, 0.46014187, 0.41240198, 0.55654373, 0.36817778,\n",
       "        0.38367593, 0.48074163, 0.38694385, 0.42378215, 0.43119197,\n",
       "        0.47135034, 0.4628796 , 0.42207378, 0.3366897 , 0.44969685,\n",
       "        0.44577251, 0.43998673, 0.46120374, 0.41647623, 0.44563818,\n",
       "        0.41853928, 0.41916479, 0.40957439, 0.49515356, 0.54499251,\n",
       "        0.42251564, 0.42579853, 0.42146918, 0.41881423, 0.34989208,\n",
       "        0.42032179, 0.37658517, 0.42312919, 0.38474012, 0.442128  ,\n",
       "        0.44365748, 0.41479618, 0.42885715, 0.43393842, 0.41511587,\n",
       "        0.43450885, 0.59536321, 0.45601391, 0.42225881, 0.51156317,\n",
       "        0.44151443, 0.4761281 , 0.36792955, 0.44398497, 0.41586014,\n",
       "        0.4388258 , 0.45634427, 0.20836866, 0.44125265, 0.86737041,\n",
       "        0.43745432, 0.43266736, 0.42934692, 0.42907071, 0.43061465,\n",
       "        0.42975159, 0.47215573, 0.42910344, 0.40657448, 0.43538229,\n",
       "        0.39920579, 0.42126107, 0.46529491, 0.39658057, 0.44426785,\n",
       "        0.43784715, 0.46184202, 0.43364773, 0.41240962, 0.40810665,\n",
       "        0.4754681 , 0.45117282, 0.46625628, 0.417277  , 0.43318069,\n",
       "        0.41658148, 0.40994081, 0.42184941, 0.45768086, 0.41256309,\n",
       "        0.47138182, 0.40917417, 0.40542563, 0.45016354, 0.42776896,\n",
       "        0.2018429 , 0.43226578, 0.44277795, 0.45019768, 0.35929741,\n",
       "        0.41250902, 0.44502528, 0.43993167, 0.39435867, 0.40967475,\n",
       "        0.42038253, 0.43205082, 0.5519255 , 0.45318042, 0.45040417,\n",
       "        0.44261894, 0.44091773, 0.40375154, 0.32442662, 0.39502642,\n",
       "        0.44570716, 0.44237586, 0.52829182, 0.49083544, 0.43115998,\n",
       "        0.34387818, 0.50307139, 0.44946168, 0.45420447, 0.36643214,\n",
       "        0.45729081, 0.40446776, 0.41766896, 0.41818607, 0.41893227,\n",
       "        0.41732177, 0.46220824, 0.43166898, 0.4019745 , 0.4266292 ,\n",
       "        0.27020171, 0.46118563, 0.46868311, 0.42249802, 0.44947305,\n",
       "        0.40666321, 0.43082876, 0.43985383, 0.41597195, 0.44246311,\n",
       "        0.42395295, 0.43538692, 0.32540083, 0.42334532, 0.42557591,\n",
       "        0.43802266, 0.45659777, 0.21000981, 0.44247046, 0.30420393,\n",
       "        0.4383837 , 0.42499718, 0.43026801, 0.45726282, 0.3827246 ,\n",
       "        0.431198  , 0.45306159, 0.41253072, 0.41712325, 0.41513355,\n",
       "        0.41200225, 0.43851883, 0.40496061, 0.37961836, 0.44151109,\n",
       "        0.37389478, 0.39705167, 0.44725287, 0.41293329, 0.40117153,\n",
       "        0.40988523, 0.45405784, 0.35684096, 0.43445893, 0.41543849,\n",
       "        0.43383879, 0.41848634, 0.45255674, 0.40319733, 0.4918455 ,\n",
       "        0.44523456, 0.41103069, 0.70883327, 0.26337543, 0.44016311,\n",
       "        0.44498239, 0.36839003, 0.44885688, 0.43429915, 0.48137866,\n",
       "        0.45651909, 0.43824794, 0.43347325, 0.47675938, 0.42303588,\n",
       "        0.44480237, 0.43069817, 0.41339586, 0.41586941, 0.42066787,\n",
       "        0.43851587, 0.41705931, 0.41624681, 0.39135426, 0.42217506,\n",
       "        0.4493727 , 0.40814486, 0.44345054, 0.43978769, 0.43086111,\n",
       "        0.49043196, 0.43924733, 0.43365392, 0.4450663 , 0.45210187,\n",
       "        0.45181671, 0.40379078, 0.42142627, 0.42611084, 0.41630125,\n",
       "        0.43885361, 0.43552938, 0.40245395, 0.45219849, 0.42323398,\n",
       "        0.41625767, 0.41485276, 0.42309069, 0.43435487, 0.45298782,\n",
       "        0.47754295, 0.46053153, 0.45045807, 0.46923521, 0.40572839,\n",
       "        0.41564965, 0.44931599, 0.43173472, 0.4462177 , 0.47780047,\n",
       "        0.42668051, 0.4352128 , 0.42510912, 0.44550546, 0.42480121,\n",
       "        0.41566039, 0.42503808, 0.24675093, 0.41891655, 0.43396778,\n",
       "        0.44253249, 0.42749747, 0.43665652, 0.36167151, 0.40688319,\n",
       "        0.43683219, 0.42528328, 0.45057888, 0.5394543 , 0.60506056,\n",
       "        0.67345482, 0.43406603, 0.40905615, 0.46021473, 0.42542053,\n",
       "        0.42460633, 0.42444432, 0.42788548, 0.4440229 , 0.45749954,\n",
       "        0.41665423, 0.40360971, 0.49866642, 0.4286966 , 0.50976461,\n",
       "        0.41067872, 0.42248685, 0.40745739, 0.43539944, 0.48062252,\n",
       "        0.44806361, 0.40862784, 0.42071244, 0.42352779, 0.40179412,\n",
       "        0.44669816, 0.44558544, 0.39800935, 0.42182773, 0.44277667,\n",
       "        0.42820622, 0.49856147, 0.46252948, 0.44567668, 0.44086923,\n",
       "        0.42441088, 0.4215208 , 0.44198465, 0.44436282, 0.63084518,\n",
       "        0.43234255, 0.41570915, 0.41879605, 0.31323088, 0.43182894,\n",
       "        0.42899087, 0.44875086, 0.43522192, 0.42992209, 0.4276689 ,\n",
       "        0.33272963, 0.44021273, 0.419056  , 0.44681966, 0.41947298,\n",
       "        0.42671445, 0.4705986 , 0.40958965, 0.45340784, 0.41277759,\n",
       "        0.64958338, 0.39014459, 0.43434202, 0.48445954, 0.43083019,\n",
       "        0.37705556, 0.47834984, 0.42026695, 0.43557902, 0.44964624,\n",
       "        0.4991921 , 0.4414086 , 0.41958278, 0.42880981, 0.44399686,\n",
       "        0.44196061, 0.44932741, 0.60591894, 0.4129794 , 0.41136562,\n",
       "        0.39609403, 0.41778951, 0.44385331, 0.43125507, 0.46844976,\n",
       "        0.43650973, 0.43368901, 0.42733374, 0.48115545, 0.46671506,\n",
       "        0.41173305, 0.44402705, 0.41333271, 0.45165505, 0.43971885,\n",
       "        0.43873319, 0.61194978, 0.43445777, 0.39284695, 0.44902584,\n",
       "        0.44057854, 0.40536922]),\n",
       " 'probW': array([0.45445873, 0.47614785, 0.4649817 , 0.46103967, 0.47128306,\n",
       "        0.47433862, 0.46155392, 0.44279562, 0.47850966, 0.42989744,\n",
       "        0.4560494 , 0.49299767, 0.45345718, 0.4542028 , 0.46025261,\n",
       "        0.45447551, 0.44004396, 0.41032062, 0.46812602, 0.48385838,\n",
       "        0.47170281, 0.46566173, 0.28093932, 0.45916924, 0.44956349,\n",
       "        0.53876748, 0.46224171, 0.48233839, 0.46829869, 0.42353928,\n",
       "        0.46569191, 0.46913168, 0.42368303, 0.48148233, 0.45267815,\n",
       "        0.46555041, 0.45265743, 0.44504532, 0.25889793, 0.45753134,\n",
       "        0.47114296, 0.50424685, 0.47627726, 0.47229957, 0.47070502,\n",
       "        0.47655593, 0.44955698, 0.4524881 , 0.48527227, 0.46238817,\n",
       "        0.44531501, 0.47895908, 0.45553638, 0.44235537, 0.45825615,\n",
       "        0.4410548 , 0.49391565, 0.46442927, 0.47593267, 0.45746342,\n",
       "        0.44611189, 0.45558394, 0.46959843, 0.46732979, 0.4654429 ,\n",
       "        0.47279973, 0.45945981, 0.46381544, 0.45772983, 0.47037384,\n",
       "        0.45579129, 0.46594946, 0.46328329, 0.46316343, 0.45589202,\n",
       "        0.46597493, 0.47971196, 0.46887214, 0.46514089, 0.45695388,\n",
       "        0.45415475, 0.44995836, 0.44968762, 0.44630873, 0.4523114 ,\n",
       "        0.4718731 , 0.46215818, 0.46916066, 0.4387779 , 0.40496834,\n",
       "        0.46014808, 0.46407156, 0.52792069, 0.45372465, 0.45109287,\n",
       "        0.50164401, 0.45920232, 0.45329683, 0.41607095, 0.41327424,\n",
       "        0.44570381, 0.44028329, 0.45612275, 0.47126039, 0.47150343,\n",
       "        0.46082425, 0.47202917, 0.46571893, 0.47505887, 0.4813965 ,\n",
       "        0.45850163, 0.47418974, 0.46581449, 0.47394487, 0.46468529,\n",
       "        0.44525044, 0.46570158, 0.42159671, 0.46329871, 0.46072155,\n",
       "        0.40777152, 0.45335646, 0.46486116, 0.45995282, 0.46618202,\n",
       "        0.45692033, 0.48402549, 0.46696146, 0.46822567, 0.41056687,\n",
       "        0.46403989, 0.44927014, 0.44993145, 0.4420859 , 0.45296916,\n",
       "        0.47394152, 0.44154497, 0.43640069, 0.43820127, 0.46243651,\n",
       "        0.42218057, 0.43414755, 0.38507986, 0.45701668, 0.42838312,\n",
       "        0.45024464, 0.45392321, 0.43828717, 0.44944887, 0.46345505,\n",
       "        0.52192905, 0.45339946, 0.45004239, 0.51043832, 0.47216925,\n",
       "        0.45963057, 0.4553079 , 0.45484047, 0.46102351, 0.45525234,\n",
       "        0.46385001, 0.43331013, 0.54958198, 0.49903997, 0.49517253,\n",
       "        0.47041565, 0.36866525, 0.46804984, 0.46113454, 0.46602708,\n",
       "        0.47107047, 0.44165787, 0.46021149, 0.45194681, 0.43724181,\n",
       "        0.45875553, 0.47713119, 0.46090315, 0.45665649, 0.46590212,\n",
       "        0.45327366, 0.48314816, 0.46718828, 0.47358298, 0.46516687,\n",
       "        0.47141499, 0.4962286 , 0.4617612 , 0.47488383, 0.5666802 ,\n",
       "        0.47987748, 0.44344622, 0.45354209, 0.44721316, 0.45444662,\n",
       "        0.29584127, 0.46756727, 0.45778323, 0.42390126, 0.46166681,\n",
       "        0.36004266, 0.44906501, 0.49988444, 0.43213723, 0.57468444,\n",
       "        0.45329451, 0.46654837, 0.45908481, 0.47620228, 0.462378  ,\n",
       "        0.41288352, 0.39965548, 0.47839331, 0.48381748, 0.50794684,\n",
       "        0.55431854, 0.47607294, 0.46515359, 0.45910821, 0.44642699,\n",
       "        0.45969808, 0.46194158, 0.47091297, 0.47002554, 0.47182514,\n",
       "        0.44713585, 0.38943857, 0.44873872, 0.45721976, 0.46138902,\n",
       "        0.45528255, 0.45159879, 0.47546862, 0.46781069, 0.46825365,\n",
       "        0.4431234 , 0.50205165, 0.49836541, 0.46171273, 0.59323876,\n",
       "        0.45933767, 0.45382617, 0.4640017 , 0.46726878, 0.46312356,\n",
       "        0.4448769 , 0.45071055, 0.45724222, 0.46194187, 0.47536026,\n",
       "        0.46494685, 0.4721968 , 0.45399329, 0.47106784, 0.46241455,\n",
       "        0.51942613, 0.47527243, 0.44472007, 0.464286  , 0.49251172,\n",
       "        0.45273781, 0.45848224, 0.55249289, 0.37070314, 0.46535077,\n",
       "        0.47101132, 0.50252654, 0.45954973, 0.4618541 , 0.45756625,\n",
       "        0.48742767, 0.47254132, 0.41540644, 0.47449799, 0.44065491,\n",
       "        0.46250838, 0.4528283 , 0.45831688, 0.43519304, 0.4623964 ,\n",
       "        0.48069907, 0.59553294, 0.44953256, 0.53569506, 0.45505262,\n",
       "        0.45102628, 0.46725989, 0.46659434, 0.47575202, 0.45546446,\n",
       "        0.44696557, 0.50167773, 0.46148367, 0.46658856, 0.42460087,\n",
       "        0.48048589, 0.46028788, 0.44734605, 0.43803794, 0.45423538,\n",
       "        0.48659242, 0.48884246, 0.44774803, 0.44076362, 0.45009828,\n",
       "        0.46387815, 0.43932438, 0.45577131, 0.45233812, 0.46385458,\n",
       "        0.45196572, 0.43381665, 0.47294933, 0.46750494, 0.50928893,\n",
       "        0.45728561, 0.44059427, 0.44598762, 0.44900874, 0.46953737,\n",
       "        0.46295481, 0.39083668, 0.42800262, 0.46868946, 0.45420005,\n",
       "        0.46033438, 0.44653728, 0.46582832, 0.46142117, 0.43980364,\n",
       "        0.47918479, 0.4681195 , 0.43305977, 0.45643067, 0.47282025,\n",
       "        0.46770628, 0.46267648, 0.45432991, 0.45724457, 0.42008487,\n",
       "        0.43816069, 0.41240376, 0.42270598, 0.46128119, 0.46414435,\n",
       "        0.46657876, 0.46395311, 0.4436973 , 0.5775791 , 0.45483382,\n",
       "        0.45266909, 0.44758416, 0.44951609, 0.47537954, 0.44330742,\n",
       "        0.45458843, 0.46178895, 0.46444585, 0.45988345, 0.48523854,\n",
       "        0.46997401, 0.46375273, 0.45856006, 0.41355571, 0.45381651,\n",
       "        0.45066401, 0.45860781, 0.44905816, 0.49377166, 0.40888294,\n",
       "        0.45708843, 0.44294609, 0.43776005, 0.45221919, 0.44365936,\n",
       "        0.43737421, 0.44125626, 0.48193999, 0.57167868, 0.41483563,\n",
       "        0.44740525, 0.44932022, 0.46108771, 0.41587364, 0.48067569,\n",
       "        0.46573136, 0.46950088, 0.45265063, 0.52544883, 0.46073988,\n",
       "        0.45778695, 0.43954316, 0.37006674, 0.48651656, 0.46020852,\n",
       "        0.46437589, 0.45223207, 0.45610213, 0.44219611, 0.48912806,\n",
       "        0.4685721 , 0.480284  , 0.46138587, 0.45015466, 0.39463348,\n",
       "        0.4594363 , 0.43754816, 0.48597845, 0.47449879, 0.47081376,\n",
       "        0.45764762, 0.49409481, 0.46260513, 0.46071737, 0.46260484,\n",
       "        0.44446166, 0.37107142, 0.46516113, 0.4351399 , 0.52734211,\n",
       "        0.44118049, 0.45175394, 0.47585381, 0.46357994, 0.4784664 ,\n",
       "        0.46047841, 0.4590575 , 0.46986093, 0.47161169, 0.33889334,\n",
       "        0.462146  , 0.44428023, 0.49218113, 0.44741651, 0.45658335,\n",
       "        0.47715626, 0.47905864, 0.46236053, 0.47458322, 0.4566724 ,\n",
       "        0.45318236, 0.45168011, 0.45611223, 0.4262735 , 0.47127716,\n",
       "        0.45747894, 0.56302096, 0.46801113, 0.44471513, 0.4693521 ,\n",
       "        0.44408071, 0.46123026, 0.45397008, 0.45694523, 0.45739445,\n",
       "        0.46544448, 0.47816895, 0.45863343, 0.50060752, 0.43424257,\n",
       "        0.46939024, 0.45295141, 0.45678687, 0.45698801, 0.4549947 ,\n",
       "        0.58567466, 0.45588534, 0.44567755, 0.45598276, 0.50020038,\n",
       "        0.46623603, 0.44995702, 0.44251451, 0.48499105, 0.46626117,\n",
       "        0.47094447, 0.44197231, 0.52441557, 0.46687113, 0.45212726,\n",
       "        0.46076898, 0.4625177 , 0.46347373, 0.43407287, 0.4540291 ,\n",
       "        0.46621264, 0.45269458, 0.46141638, 0.53632028, 0.4451506 ,\n",
       "        0.46428602, 0.44284168, 0.47096169, 0.46414893, 0.41609112,\n",
       "        0.44780318, 0.50160235, 0.47201667, 0.46685264, 0.47609175,\n",
       "        0.48474128, 0.42586475, 0.45567477, 0.45775445, 0.47159773,\n",
       "        0.50735568, 0.45788733, 0.49743521, 0.45428253, 0.47367477,\n",
       "        0.46491563, 0.46404031, 0.4621009 , 0.4677521 , 0.45526616,\n",
       "        0.47424807, 0.45992485, 0.48527907, 0.45907739, 0.44619636,\n",
       "        0.46751667, 0.46686127, 0.48915128, 0.45406135, 0.45952467,\n",
       "        0.48597277, 0.4661537 , 0.49500253, 0.45715259, 0.47489815,\n",
       "        0.4634302 , 0.4238736 , 0.4568741 , 0.46178618, 0.46314754,\n",
       "        0.48074715, 0.38090342, 0.46296086, 0.45579511, 0.4497057 ,\n",
       "        0.52562512, 0.43832425, 0.46141363, 0.42753235, 0.44494099,\n",
       "        0.46076802, 0.4562335 , 0.43324943, 0.46806359, 0.48021175,\n",
       "        0.47712309, 0.46294801, 0.46736658, 0.50761504, 0.45441041,\n",
       "        0.47785081, 0.44669072, 0.40890313, 0.46932659, 0.45860919,\n",
       "        0.4369491 , 0.43685868, 0.46265765, 0.44496767, 0.51146669,\n",
       "        0.43826876, 0.45771705, 0.44849129, 0.46621056, 0.47200229,\n",
       "        0.45591333, 0.46605623, 0.46454475, 0.453367  , 0.46477349,\n",
       "        0.47308858, 0.46196085, 0.46271138, 0.44645536, 0.46057859,\n",
       "        0.45302801, 0.46008318, 0.49124327, 0.44087413, 0.4573142 ,\n",
       "        0.48823668, 0.46289283, 0.470868  , 0.46725639, 0.45175412,\n",
       "        0.49414655, 0.46891248, 0.46047315, 0.46747639, 0.4913121 ,\n",
       "        0.45627218, 0.4672283 , 0.45868623, 0.45304865, 0.48834666,\n",
       "        0.46673501, 0.47194618, 0.44231925, 0.45174459, 0.41895423,\n",
       "        0.56492758, 0.46341866, 0.44563852, 0.48055328, 0.43632171,\n",
       "        0.48251678, 0.45176666, 0.46223319, 0.42939499, 0.45777918,\n",
       "        0.44835465, 0.49031607, 0.45492752, 0.4644125 , 0.43732285,\n",
       "        0.46513901, 0.47519986, 0.44804127, 0.44924832, 0.49006976,\n",
       "        0.45631864, 0.46123919, 0.46534126, 0.48229998, 0.45616023,\n",
       "        0.4525647 , 0.45001043, 0.46730553, 0.37310581, 0.4618427 ,\n",
       "        0.46444587, 0.46060224, 0.46317477, 0.46218829, 0.47154568,\n",
       "        0.45672256, 0.48167353, 0.47335802, 0.45854872, 0.45139224,\n",
       "        0.45471925, 0.46941212, 0.47468757, 0.46851168, 0.39915946,\n",
       "        0.45809977, 0.46152806, 0.52938444, 0.47373499, 0.46087951,\n",
       "        0.47063557, 0.46477639, 0.4839509 , 0.44354773, 0.45108333,\n",
       "        0.46307072, 0.46374497, 0.45902672, 0.45388458, 0.49440243,\n",
       "        0.4700139 , 0.46771355, 0.47377185, 0.46057067, 0.44605714,\n",
       "        0.45484846, 0.44875866, 0.44459759, 0.46606095, 0.40904492,\n",
       "        0.4627669 , 0.47503528, 0.45900233, 0.43193088, 0.48270298,\n",
       "        0.43016136, 0.47040896, 0.48352747, 0.4215864 , 0.44427489,\n",
       "        0.44048928, 0.46349765, 0.45133921, 0.46593808, 0.46592892,\n",
       "        0.45413669, 0.46210665, 0.46819534, 0.47144928, 0.44887007,\n",
       "        0.46896281, 0.51861819, 0.45125545, 0.46977952, 0.45513732,\n",
       "        0.48031184, 0.50672739, 0.44583519, 0.45172985, 0.45535332,\n",
       "        0.47176905, 0.46093655, 0.48245751, 0.4676071 , 0.47268691,\n",
       "        0.50798564, 0.44760259, 0.46565155, 0.48285576, 0.4619305 ,\n",
       "        0.45060363, 0.47004352, 0.46721284, 0.46436225, 0.45973699,\n",
       "        0.45981237, 0.46884192, 0.45834596, 0.47969182, 0.47608642,\n",
       "        0.46077455, 0.44829731, 0.44717605, 0.46008895, 0.46353691,\n",
       "        0.46400287, 0.46050376, 0.46383755, 0.44411344, 0.46443438,\n",
       "        0.46635217, 0.459082  ]),\n",
       " 'temp': array([1.62102745, 1.27967114, 1.44292601, 1.38603885, 1.18731638,\n",
       "        1.13908555, 1.28173397, 1.26210443, 1.36286031, 1.70105887,\n",
       "        1.57317939, 1.35853876, 1.42668051, 1.41709124, 1.24678379,\n",
       "        1.3494312 , 1.26015324, 1.43121799, 1.39671832, 1.33216924,\n",
       "        1.23766536, 1.64607122, 0.68771758, 1.42662339, 1.34397291,\n",
       "        1.02066666, 1.4133628 , 1.45610383, 1.25716682, 1.55806888,\n",
       "        1.46670817, 1.36553409, 1.43237804, 1.72171933, 1.28856523,\n",
       "        1.28799373, 1.44968894, 1.44066956, 0.84365026, 1.39758749,\n",
       "        1.04904854, 1.55587738, 1.25186095, 1.37379587, 1.4218336 ,\n",
       "        1.74459597, 1.33274665, 1.42468263, 1.49605419, 1.0937404 ,\n",
       "        1.38007329, 1.33131593, 1.35313145, 1.65425883, 1.39733912,\n",
       "        1.29002934, 1.10843297, 1.47271688, 1.33445756, 1.22050145,\n",
       "        1.560611  , 1.48592336, 1.41229547, 1.31894772, 1.54540735,\n",
       "        1.29420545, 1.3510206 , 1.45481992, 1.36382789, 1.38527751,\n",
       "        1.57523849, 1.27520568, 1.34711999, 1.35566257, 1.42302158,\n",
       "        1.32756117, 1.3344308 , 1.32821257, 1.31143269, 1.41422479,\n",
       "        1.34098532, 1.22330282, 1.31181708, 1.42344687, 1.44993024,\n",
       "        1.5077157 , 1.63259054, 1.26622359, 1.6010854 , 1.39455731,\n",
       "        1.46205371, 1.38574516, 0.67995181, 1.37866133, 1.37287065,\n",
       "        1.13648241, 1.39288857, 1.41949965, 1.41166133, 0.78393599,\n",
       "        1.34632232, 1.64143584, 1.45215944, 1.2652337 , 1.52665988,\n",
       "        1.38230762, 1.40333233, 1.3216449 , 1.19066435, 1.31188827,\n",
       "        0.77524979, 1.38565519, 1.4125482 , 1.41882303, 1.40728753,\n",
       "        1.12043404, 1.4855853 , 1.32681005, 1.47588965, 1.35513957,\n",
       "        1.39320121, 1.47925241, 1.26370509, 1.48820691, 1.16892561,\n",
       "        1.399376  , 1.21247733, 1.29114354, 1.42674796, 1.36290884,\n",
       "        1.21825791, 1.33853054, 1.32712656, 1.39818101, 1.33035678,\n",
       "        1.41313812, 1.52321299, 1.26496996, 1.3627955 , 1.39333986,\n",
       "        1.66466008, 1.38365039, 1.41718435, 1.36364166, 1.69413092,\n",
       "        1.3153608 , 1.46662538, 1.24794821, 1.25131861, 1.52943936,\n",
       "        1.27650602, 1.35581336, 1.44112388, 0.74900744, 1.3447781 ,\n",
       "        1.16610652, 1.45625575, 1.36419813, 1.25798617, 1.40849586,\n",
       "        1.48452395, 1.38287947, 1.15065412, 1.23787189, 1.47360784,\n",
       "        1.29291233, 1.35869325, 1.40227384, 1.14745483, 1.39415295,\n",
       "        1.52195329, 1.43624719, 1.39941052, 1.32152211, 1.46414356,\n",
       "        1.32891542, 1.3019441 , 1.37020248, 1.48650663, 1.45540545,\n",
       "        1.31349631, 1.31284474, 1.58222937, 1.52121252, 1.32608295,\n",
       "        1.44938112, 1.28252562, 3.99345661, 1.31058193, 1.32946085,\n",
       "        1.42632643, 1.4235693 , 1.37094316, 1.21888736, 1.50365295,\n",
       "        1.85200523, 1.28558007, 1.42907599, 1.0605525 , 1.28507486,\n",
       "        1.20555615, 1.59205022, 1.29509631, 1.22309353, 0.96662325,\n",
       "        1.52719872, 1.32587115, 1.1918164 , 1.32303481, 1.45658961,\n",
       "        2.72010198, 0.9075393 , 1.35824504, 1.26482318, 2.78317203,\n",
       "        1.08476087, 1.37017197, 1.36372724, 1.28021372, 1.3717095 ,\n",
       "        1.37600602, 1.37119248, 1.31881368, 1.40285213, 1.41354117,\n",
       "        1.61234941, 1.09098353, 1.22804504, 1.43820944, 1.38077298,\n",
       "        1.44499037, 1.33493929, 1.35434324, 1.38615516, 1.34714864,\n",
       "        1.53885769, 1.20985002, 1.11428534, 1.36466555, 1.11290579,\n",
       "        1.45511998, 1.45506484, 1.42164864, 1.35277625, 1.41586411,\n",
       "        1.40032844, 1.30882473, 1.36444123, 1.27793206, 1.3421516 ,\n",
       "        1.42996096, 1.4285309 , 1.28333445, 1.55323572, 1.98031496,\n",
       "        0.94728585, 1.30231804, 1.04178361, 1.87853975, 1.33654527,\n",
       "        1.40103249, 1.34843821, 0.83245111, 1.64477473, 3.48403953,\n",
       "        1.42585861, 0.86648293, 1.47454417, 1.52622051, 1.19703419,\n",
       "        1.22555404, 1.47036398, 1.05455741, 1.62374953, 1.27893521,\n",
       "        1.39708837, 1.23677335, 1.47980015, 1.48632556, 1.32908626,\n",
       "        1.13881797, 0.76554197, 1.4515251 , 1.41661892, 1.364211  ,\n",
       "        1.40156312, 0.92872491, 1.51938563, 1.3520811 , 1.46600974,\n",
       "        1.77507066, 1.22784846, 1.5273159 , 1.37535083, 1.29887894,\n",
       "        1.30290267, 1.41973541, 1.41209974, 1.41025241, 1.33825271,\n",
       "        1.34819983, 1.17589537, 1.35946874, 1.32909097, 1.28670151,\n",
       "        1.68553752, 1.51156092, 1.47940549, 1.35050657, 1.35849342,\n",
       "        1.57028897, 1.88857586, 1.54106316, 1.42000511, 1.27519161,\n",
       "        1.47562653, 1.3558138 , 1.37929649, 1.38517777, 1.2422979 ,\n",
       "        1.2647125 , 1.25433439, 1.4573421 , 1.3877026 , 1.35032491,\n",
       "        1.36282567, 1.31409558, 1.50096473, 1.50543497, 1.44044767,\n",
       "        1.43912367, 1.53099647, 1.50066801, 1.41358969, 1.39405534,\n",
       "        1.45977321, 1.47625219, 1.39811642, 1.4200475 , 1.38863852,\n",
       "        1.46084662, 1.31872226, 1.47250788, 1.40326863, 1.37323069,\n",
       "        1.3805013 , 1.23358101, 1.49651199, 1.47210324, 1.41160398,\n",
       "        1.35057051, 1.3089051 , 1.33011702, 1.47186097, 0.94597777,\n",
       "        1.39982136, 1.37882311, 1.36410057, 1.28948096, 1.43087154,\n",
       "        1.47508869, 1.43758785, 1.43023357, 1.54514144, 1.22325175,\n",
       "        1.41055535, 1.41683345, 1.27829577, 1.30814363, 1.68395915,\n",
       "        1.28648798, 1.22327929, 1.43272726, 1.29751692, 1.34898054,\n",
       "        1.26743908, 1.59304435, 1.2904315 , 1.20679527, 1.45941179,\n",
       "        1.3072966 , 1.65949855, 1.38678575, 1.70871901, 1.11948955,\n",
       "        1.39194958, 1.53249025, 1.51890884, 0.90193818, 1.24946696,\n",
       "        1.25883445, 1.38334589, 1.22434277, 1.31669518, 1.42432203,\n",
       "        1.46521178, 1.80648271, 1.34120882, 1.35919383, 1.18393302,\n",
       "        1.37954981, 1.17782344, 1.52419056, 1.58498964, 1.12754848,\n",
       "        1.38383983, 1.3660988 , 1.48800279, 1.20870151, 1.47173128,\n",
       "        1.53180931, 1.41940364, 1.49173894, 1.40710622, 1.38929203,\n",
       "        1.40515333, 1.07062123, 1.38509848, 1.3974646 , 0.91894833,\n",
       "        1.02663918, 1.25571492, 1.56711001, 1.25136532, 2.0290084 ,\n",
       "        1.21024173, 1.37789322, 1.34950027, 1.30058627, 1.0222342 ,\n",
       "        1.41390102, 1.23798393, 1.15942699, 1.4710425 , 1.40732001,\n",
       "        1.38128229, 1.42145602, 1.39479478, 1.43165819, 1.36150257,\n",
       "        1.52919599, 1.10492938, 1.41376986, 1.47267785, 1.37140269,\n",
       "        1.3368728 , 1.27748035, 1.21778433, 1.54859197, 1.38640076,\n",
       "        1.44175407, 1.27437183, 1.34393324, 1.34258764, 1.42062953,\n",
       "        1.34561586, 1.28581679, 1.46584282, 1.27884581, 1.46466584,\n",
       "        1.53643092, 1.31727233, 1.47458007, 1.44422731, 1.35498705,\n",
       "        0.86264785, 1.32605805, 1.39498456, 1.35453217, 0.87713487,\n",
       "        1.21323271, 1.48855455, 1.41645362, 1.3466472 , 1.33868159,\n",
       "        1.39185649, 1.3856769 , 1.81388682, 1.27363953, 1.39688834,\n",
       "        1.19808316, 1.39216742, 1.32598994, 1.18544337, 1.44753775,\n",
       "        1.44166236, 1.24265903, 1.30452515, 1.15446846, 1.56642869,\n",
       "        1.06450618, 1.1696895 , 1.45791156, 1.30607123, 0.97421057,\n",
       "        1.64908883, 1.27910219, 1.22503321, 1.35608029, 1.49391104,\n",
       "        1.25329962, 1.51554622, 1.36463907, 1.34203713, 1.47712098,\n",
       "        1.32682936, 1.35489732, 0.83636085, 1.30541253, 1.03941617,\n",
       "        1.32114488, 1.28975601, 1.38900017, 1.4805081 , 1.445107  ,\n",
       "        1.37567614, 1.50515888, 1.18577688, 1.46922872, 1.30889098,\n",
       "        1.38674079, 1.37073687, 2.52582931, 1.38660453, 0.82662554,\n",
       "        1.25044738, 1.38020161, 1.33537008, 1.2975922 , 1.2881377 ,\n",
       "        1.24492334, 1.61021171, 1.23751454, 1.41099117, 1.33468352,\n",
       "        1.4498693 , 1.99306842, 1.52158026, 1.33988252, 1.5246446 ,\n",
       "        1.27723184, 1.28527337, 1.47582101, 1.26432517, 1.39110288,\n",
       "        1.68447421, 1.39174557, 1.17463207, 1.37170422, 1.79144501,\n",
       "        1.45615136, 1.32744169, 1.447602  , 1.40200583, 1.86521981,\n",
       "        1.36100493, 1.36136991, 0.7769733 , 0.87313927, 1.44288377,\n",
       "        1.43139248, 1.13543272, 1.36220631, 1.35899727, 1.31058121,\n",
       "        1.19938669, 1.38953123, 1.33062717, 1.79069279, 1.37881204,\n",
       "        2.13803609, 1.47424581, 1.31966424, 1.29559357, 1.18761269,\n",
       "        1.33360932, 1.36623377, 1.3867971 , 1.3326949 , 1.38694237,\n",
       "        1.40303062, 1.35032536, 1.2257673 , 1.42464301, 1.33942337,\n",
       "        1.18096811, 1.34047582, 1.38376253, 1.60933318, 1.33547793,\n",
       "        1.38154784, 1.42791731, 1.35869129, 1.33787696, 1.21435785,\n",
       "        1.39364235, 1.40537454, 1.44820122, 1.35939678, 1.29274649,\n",
       "        1.34723751, 1.35329389, 1.39258303, 1.31857059, 1.50645557,\n",
       "        1.29005225, 1.37240551, 1.6358225 , 1.51560209, 1.1989807 ,\n",
       "        1.34150662, 1.56521517, 1.45331821, 1.43320062, 1.62268293,\n",
       "        1.34153326, 1.5289284 , 1.35876632, 1.24854733, 1.46269359,\n",
       "        1.35279536, 1.26917521, 0.68387675, 1.39365808, 1.35562448,\n",
       "        1.35779667, 1.23451245, 1.43739265, 1.27836636, 1.37471291,\n",
       "        1.39308241, 1.38471236, 1.27229897, 1.27131159, 1.06450276,\n",
       "        1.98927819, 1.34440744, 1.25276459, 1.73873791, 1.16892285,\n",
       "        1.49337387, 1.18742663, 1.37970665, 1.54838044, 1.30026075,\n",
       "        1.47916949, 1.37579854, 1.67221125, 1.33072591, 0.99569011,\n",
       "        1.42171251, 1.38161869, 1.33182668, 1.32658864, 1.44210612,\n",
       "        1.37316294, 1.37286072, 1.35988233, 1.50122717, 1.4877569 ,\n",
       "        1.44222811, 1.45070869, 1.6459936 , 1.47535178, 1.24182839,\n",
       "        1.366813  , 1.4417292 , 1.33696938, 1.52399563, 1.28065976,\n",
       "        1.46291496, 1.50803327, 1.44360238, 1.368613  , 2.71091218,\n",
       "        1.48668604, 1.37114022, 1.3137117 , 1.53030041, 0.7651912 ,\n",
       "        1.04194617, 1.35262744, 1.24110751, 1.28136479, 1.35802694,\n",
       "        1.26997582, 1.39888197, 1.37293189, 1.03825573, 1.45329772,\n",
       "        1.24247647, 1.40984529, 1.2774934 , 1.47285315, 1.48701973,\n",
       "        1.26173853, 1.55744822, 1.45673043, 1.24141806, 1.45720182,\n",
       "        1.42122915, 1.36847499, 2.00923949, 1.38042945, 1.33944182,\n",
       "        1.50667719, 1.33214344, 1.21601446, 1.49173582, 1.33919028,\n",
       "        1.48762227, 1.31720192, 2.13467275, 1.2107972 , 1.37787153,\n",
       "        1.27269271, 1.3114129 , 1.40294092, 1.40492429, 1.54259612,\n",
       "        1.38221894, 1.38330691, 1.44400327, 1.47118052, 1.68714136,\n",
       "        1.40398028, 1.38354303, 1.20218554, 1.42875573, 1.49291072,\n",
       "        1.400047  , 1.39695081, 1.34399824, 1.27984734, 1.30779965,\n",
       "        1.41457503, 1.18211193])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.simuIndivParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('models_prob_weigh/normal.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   0.,   4.,   0.,   2.,   3.,   1.,   1.,   0.,   3.,\n",
       "          3.,   3.,   5.,  10.,  12.,  25.,  65., 147., 162., 141.,  60.,\n",
       "         35.,  13.,  13.,   3.,   3.,   4.,   3.,   2.,   2.,   3.,   1.,\n",
       "          1.,   1.,   1.,   1.,   0.,   1.,   1.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   1.]),\n",
       " array([0.15515893, 0.16940316, 0.18364739, 0.19789162, 0.21213585,\n",
       "        0.22638008, 0.24062431, 0.25486854, 0.26911277, 0.283357  ,\n",
       "        0.29760123, 0.31184546, 0.32608969, 0.34033392, 0.35457815,\n",
       "        0.36882238, 0.38306661, 0.39731084, 0.41155506, 0.42579929,\n",
       "        0.44004352, 0.45428775, 0.46853198, 0.48277621, 0.49702044,\n",
       "        0.51126467, 0.5255089 , 0.53975313, 0.55399736, 0.56824159,\n",
       "        0.58248582, 0.59673005, 0.61097428, 0.62521851, 0.63946274,\n",
       "        0.65370697, 0.6679512 , 0.68219542, 0.69643965, 0.71068388,\n",
       "        0.72492811, 0.73917234, 0.75341657, 0.7676608 , 0.78190503,\n",
       "        0.79614926, 0.81039349, 0.82463772, 0.83888195, 0.85312618,\n",
       "        0.86737041]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model.simu_indiv_params['riskCoef'],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   0.,   1.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,\n",
       "          1.,   0.,   0.,   0.,   1.,   5.,   0.,   2.,   2.,   3.,   1.,\n",
       "         10.,   7.,  11.,  12.,  29.,  56.,  88., 130., 156.,  85.,  45.,\n",
       "         26.,  17.,   9.,  11.,   3.,   2.,   6.,   1.,   3.,   0.,   3.,\n",
       "          0.,   3.,   2.,   1.,   1.,   2.]),\n",
       " array([0.25889793, 0.26563063, 0.27236333, 0.27909603, 0.28582873,\n",
       "        0.29256143, 0.29929413, 0.30602683, 0.31275953, 0.31949223,\n",
       "        0.32622494, 0.33295764, 0.33969034, 0.34642304, 0.35315574,\n",
       "        0.35988844, 0.36662114, 0.37335384, 0.38008654, 0.38681924,\n",
       "        0.39355194, 0.40028464, 0.40701734, 0.41375004, 0.42048274,\n",
       "        0.42721544, 0.43394814, 0.44068084, 0.44741354, 0.45414624,\n",
       "        0.46087894, 0.46761164, 0.47434434, 0.48107704, 0.48780974,\n",
       "        0.49454244, 0.50127514, 0.50800784, 0.51474054, 0.52147324,\n",
       "        0.52820594, 0.53493864, 0.54167134, 0.54840404, 0.55513674,\n",
       "        0.56186944, 0.56860214, 0.57533484, 0.58206754, 0.58880024,\n",
       "        0.59553294]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model.simu_indiv_params['probW'],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   0.,   0.,   2.,   2.,   1.,   1.,   4.,   0.,   0.,\n",
       "          1.,   4.,   2.,   6.,   4.,   7.,   8.,  19.,  32.,  38.,  69.,\n",
       "         98.,  95., 115.,  86.,  44.,  26.,  21.,  13.,   6.,   9.,   8.,\n",
       "          2.,   1.,   2.,   1.,   1.,   2.,   1.,   1.,   1.,   0.,   1.,\n",
       "          0.,   0.,   0.,   1.,   0.,   1.]),\n",
       " array([0.51168028, 0.54464209, 0.57760389, 0.6105657 , 0.64352751,\n",
       "        0.67648931, 0.70945112, 0.74241293, 0.77537474, 0.80833654,\n",
       "        0.84129835, 0.87426016, 0.90722197, 0.94018377, 0.97314558,\n",
       "        1.00610739, 1.0390692 , 1.072031  , 1.10499281, 1.13795462,\n",
       "        1.17091643, 1.20387823, 1.23684004, 1.26980185, 1.30276365,\n",
       "        1.33572546, 1.36868727, 1.40164908, 1.43461088, 1.46757269,\n",
       "        1.5005345 , 1.53349631, 1.56645811, 1.59941992, 1.63238173,\n",
       "        1.66534354, 1.69830534, 1.73126715, 1.76422896, 1.79719077,\n",
       "        1.83015257, 1.86311438, 1.89607619, 1.92903799, 1.9619998 ,\n",
       "        1.99496161, 2.02792342, 2.06088522, 2.09384703, 2.12680884,\n",
       "        2.15977065]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model.simu_indiv_params['temp'],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>WLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>ratio_indiv_stock</td> <th>  R-squared:         </th> <td>   0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>WLS</td>        <th>  Adj. R-squared:    </th> <td>   0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   4.899</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 21 Jan 2025</td>  <th>  Prob (F-statistic):</th> <td>2.23e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:08:47</td>      <th>  Log-Likelihood:    </th> <td> -456.61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   737</td>       <th>  AIC:               </th> <td>   955.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   716</td>       <th>  BIC:               </th> <td>   1052.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    20</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>    0.3358</td> <td>    0.129</td> <td>    2.603</td> <td> 0.009</td> <td>    0.082</td> <td>    0.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_probW</th>        <td>   -0.1369</td> <td>    0.050</td> <td>   -2.738</td> <td> 0.006</td> <td>   -0.235</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_riskCoef</th>     <td>    0.1183</td> <td>    0.062</td> <td>    1.922</td> <td> 0.055</td> <td>   -0.003</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                <td>    0.0061</td> <td>    0.006</td> <td>    0.999</td> <td> 0.318</td> <td>   -0.006</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age2</th>               <td>-5.575e-05</td> <td> 5.91e-05</td> <td>   -0.943</td> <td> 0.346</td> <td>   -0.000</td> <td> 6.03e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>male</th>               <td>    0.0717</td> <td>    0.031</td> <td>    2.326</td> <td> 0.020</td> <td>    0.011</td> <td>    0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>married</th>            <td>   -0.0351</td> <td>    0.036</td> <td>   -0.967</td> <td> 0.334</td> <td>   -0.106</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>white</th>              <td>   -0.1223</td> <td>    0.048</td> <td>   -2.531</td> <td> 0.012</td> <td>   -0.217</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hispanic</th>           <td>    0.1092</td> <td>    0.065</td> <td>    1.686</td> <td> 0.092</td> <td>   -0.018</td> <td>    0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>employed</th>           <td>   -0.0434</td> <td>    0.045</td> <td>   -0.972</td> <td> 0.331</td> <td>   -0.131</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>householdmembers</th>   <td>   -0.0136</td> <td>    0.014</td> <td>   -0.946</td> <td> 0.345</td> <td>   -0.042</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_college_degree</th>  <td>    0.1638</td> <td>    0.048</td> <td>    3.382</td> <td> 0.001</td> <td>    0.069</td> <td>    0.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bachelor_degree</th>    <td>    0.1341</td> <td>    0.047</td> <td>    2.847</td> <td> 0.005</td> <td>    0.042</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>master_degree</th>      <td>    0.0379</td> <td>    0.050</td> <td>    0.763</td> <td> 0.446</td> <td>   -0.060</td> <td>    0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>familyincome_value</th> <td>    0.0515</td> <td>    0.020</td> <td>    2.635</td> <td> 0.009</td> <td>    0.013</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fin_wealth</th>         <td>   -0.0318</td> <td>    0.008</td> <td>   -3.892</td> <td> 0.000</td> <td>   -0.048</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fin_literacy</th>       <td>   -0.0140</td> <td>    0.017</td> <td>   -0.838</td> <td> 0.402</td> <td>   -0.047</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numeracy</th>           <td>    0.0393</td> <td>    0.014</td> <td>    2.735</td> <td> 0.006</td> <td>    0.011</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>trust</th>              <td>    0.0320</td> <td>    0.015</td> <td>    2.130</td> <td> 0.033</td> <td>    0.003</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>optimism</th>           <td>   -0.0369</td> <td>    0.011</td> <td>   -3.222</td> <td> 0.001</td> <td>   -0.059</td> <td>   -0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gambling</th>           <td>    0.0158</td> <td>    0.030</td> <td>    0.523</td> <td> 0.601</td> <td>   -0.043</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>missing_value</th>      <td>    0.0065</td> <td>    0.045</td> <td>    0.144</td> <td> 0.885</td> <td>   -0.082</td> <td>    0.095</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.126</td> <th>  Durbin-Watson:     </th> <td>   1.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.127</td> <th>  Jarque-Bera (JB):  </th> <td>   3.340</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.054</td> <th>  Prob(JB):          </th> <td>   0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.688</td> <th>  Cond. No.          </th> <td>2.20e+19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.44e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}      & ratio\\_indiv\\_stock & \\textbf{  R-squared:         } &     0.120   \\\\\n",
       "\\textbf{Model:}              &         WLS         & \\textbf{  Adj. R-squared:    } &     0.096   \\\\\n",
       "\\textbf{Method:}             &    Least Squares    & \\textbf{  F-statistic:       } &     4.899   \\\\\n",
       "\\textbf{Date:}               &   Tue, 21 Jan 2025  & \\textbf{  Prob (F-statistic):} &  2.23e-11   \\\\\n",
       "\\textbf{Time:}               &       16:08:47      & \\textbf{  Log-Likelihood:    } &   -456.61   \\\\\n",
       "\\textbf{No. Observations:}   &           737       & \\textbf{  AIC:               } &     955.2   \\\\\n",
       "\\textbf{Df Residuals:}       &           716       & \\textbf{  BIC:               } &     1052.   \\\\\n",
       "\\textbf{Df Model:}           &            20       & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}    &      nonrobust      & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                             & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}               &       0.3358  &        0.129     &     2.603  &         0.009        &        0.082    &        0.589     \\\\\n",
       "\\textbf{class\\_probW}        &      -0.1369  &        0.050     &    -2.738  &         0.006        &       -0.235    &       -0.039     \\\\\n",
       "\\textbf{class\\_riskCoef}     &       0.1183  &        0.062     &     1.922  &         0.055        &       -0.003    &        0.239     \\\\\n",
       "\\textbf{age}                 &       0.0061  &        0.006     &     0.999  &         0.318        &       -0.006    &        0.018     \\\\\n",
       "\\textbf{age2}                &   -5.575e-05  &     5.91e-05     &    -0.943  &         0.346        &       -0.000    &     6.03e-05     \\\\\n",
       "\\textbf{male}                &       0.0717  &        0.031     &     2.326  &         0.020        &        0.011    &        0.132     \\\\\n",
       "\\textbf{married}             &      -0.0351  &        0.036     &    -0.967  &         0.334        &       -0.106    &        0.036     \\\\\n",
       "\\textbf{white}               &      -0.1223  &        0.048     &    -2.531  &         0.012        &       -0.217    &       -0.027     \\\\\n",
       "\\textbf{hispanic}            &       0.1092  &        0.065     &     1.686  &         0.092        &       -0.018    &        0.236     \\\\\n",
       "\\textbf{employed}            &      -0.0434  &        0.045     &    -0.972  &         0.331        &       -0.131    &        0.044     \\\\\n",
       "\\textbf{householdmembers}    &      -0.0136  &        0.014     &    -0.946  &         0.345        &       -0.042    &        0.015     \\\\\n",
       "\\textbf{no\\_college\\_degree} &       0.1638  &        0.048     &     3.382  &         0.001        &        0.069    &        0.259     \\\\\n",
       "\\textbf{bachelor\\_degree}    &       0.1341  &        0.047     &     2.847  &         0.005        &        0.042    &        0.227     \\\\\n",
       "\\textbf{master\\_degree}      &       0.0379  &        0.050     &     0.763  &         0.446        &       -0.060    &        0.135     \\\\\n",
       "\\textbf{familyincome\\_value} &       0.0515  &        0.020     &     2.635  &         0.009        &        0.013    &        0.090     \\\\\n",
       "\\textbf{fin\\_wealth}         &      -0.0318  &        0.008     &    -3.892  &         0.000        &       -0.048    &       -0.016     \\\\\n",
       "\\textbf{fin\\_literacy}       &      -0.0140  &        0.017     &    -0.838  &         0.402        &       -0.047    &        0.019     \\\\\n",
       "\\textbf{numeracy}            &       0.0393  &        0.014     &     2.735  &         0.006        &        0.011    &        0.067     \\\\\n",
       "\\textbf{trust}               &       0.0320  &        0.015     &     2.130  &         0.033        &        0.003    &        0.062     \\\\\n",
       "\\textbf{optimism}            &      -0.0369  &        0.011     &    -3.222  &         0.001        &       -0.059    &       -0.014     \\\\\n",
       "\\textbf{gambling}            &       0.0158  &        0.030     &     0.523  &         0.601        &       -0.043    &        0.075     \\\\\n",
       "\\textbf{missing\\_value}      &       0.0065  &        0.045     &     0.144  &         0.885        &       -0.082    &        0.095     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  4.126 & \\textbf{  Durbin-Watson:     } &    1.965  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.127 & \\textbf{  Jarque-Bera (JB):  } &    3.340  \\\\\n",
       "\\textbf{Skew:}          & -0.054 & \\textbf{  Prob(JB):          } &    0.188  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.688 & \\textbf{  Cond. No.          } & 2.20e+19  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{WLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 1.44e-29. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            WLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:      ratio_indiv_stock   R-squared:                       0.120\n",
       "Model:                            WLS   Adj. R-squared:                  0.096\n",
       "Method:                 Least Squares   F-statistic:                     4.899\n",
       "Date:                Tue, 21 Jan 2025   Prob (F-statistic):           2.23e-11\n",
       "Time:                        16:08:47   Log-Likelihood:                -456.61\n",
       "No. Observations:                 737   AIC:                             955.2\n",
       "Df Residuals:                     716   BIC:                             1052.\n",
       "Df Model:                          20                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                  0.3358      0.129      2.603      0.009       0.082       0.589\n",
       "class_probW           -0.1369      0.050     -2.738      0.006      -0.235      -0.039\n",
       "class_riskCoef         0.1183      0.062      1.922      0.055      -0.003       0.239\n",
       "age                    0.0061      0.006      0.999      0.318      -0.006       0.018\n",
       "age2               -5.575e-05   5.91e-05     -0.943      0.346      -0.000    6.03e-05\n",
       "male                   0.0717      0.031      2.326      0.020       0.011       0.132\n",
       "married               -0.0351      0.036     -0.967      0.334      -0.106       0.036\n",
       "white                 -0.1223      0.048     -2.531      0.012      -0.217      -0.027\n",
       "hispanic               0.1092      0.065      1.686      0.092      -0.018       0.236\n",
       "employed              -0.0434      0.045     -0.972      0.331      -0.131       0.044\n",
       "householdmembers      -0.0136      0.014     -0.946      0.345      -0.042       0.015\n",
       "no_college_degree      0.1638      0.048      3.382      0.001       0.069       0.259\n",
       "bachelor_degree        0.1341      0.047      2.847      0.005       0.042       0.227\n",
       "master_degree          0.0379      0.050      0.763      0.446      -0.060       0.135\n",
       "familyincome_value     0.0515      0.020      2.635      0.009       0.013       0.090\n",
       "fin_wealth            -0.0318      0.008     -3.892      0.000      -0.048      -0.016\n",
       "fin_literacy          -0.0140      0.017     -0.838      0.402      -0.047       0.019\n",
       "numeracy               0.0393      0.014      2.735      0.006       0.011       0.067\n",
       "trust                  0.0320      0.015      2.130      0.033       0.003       0.062\n",
       "optimism              -0.0369      0.011     -3.222      0.001      -0.059      -0.014\n",
       "gambling               0.0158      0.030      0.523      0.601      -0.043       0.075\n",
       "missing_value          0.0065      0.045      0.144      0.885      -0.082       0.095\n",
       "==============================================================================\n",
       "Omnibus:                        4.126   Durbin-Watson:                   1.965\n",
       "Prob(Omnibus):                  0.127   Jarque-Bera (JB):                3.340\n",
       "Skew:                          -0.054   Prob(JB):                        0.188\n",
       "Kurtosis:                       2.688   Cond. No.                     2.20e+19\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.44e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = pickle.load(open('ProbWeigh_normal_new.pkl', 'rb'))\n",
    "# df_equity['riskCoef'] = model.simu_indiv_params['riskCoef']\n",
    "# df_equity['probW'] = model.simu_indiv_params['probW']\n",
    "# df_equity['temp'] = model.simu_indiv_params['temp']\n",
    "\n",
    "\n",
    "model = pickle.load(open('models_prob_weigh/pw_class_5.pkl', 'rb'))\n",
    "df_equity['class_probW'] = (model.post_prob * model.latent_class['probW']).sum(axis=1)\n",
    "df_equity['class_riskCoef'] = (model.post_prob * model.latent_class['riskCoef']).sum(axis=1)\n",
    "# df_equity['class_temp'] = (model.post_prob * model.latent_class['temp']).sum(axis=1)\n",
    "# df_equity['class_prob'] = model.post_prob[:,0]\n",
    "\n",
    "df_reg_normal = pd.merge(left=df_reg,right=df_equity[['prim_key','weight','class_probW','class_riskCoef']],\n",
    "                        on=['prim_key','weight'])\n",
    "\n",
    "endog = df_reg_normal['ratio_indiv_stock']\n",
    "\n",
    "new_exog_cols = [x for x in exog_cols if x not in ['inverse_S','riskaversion']]\n",
    "\n",
    "# exog = sm.add_constant(df_reg_normal[['probW','riskCoef','temp'] + new_exog_cols])\n",
    "exog = sm.add_constant(df_reg_normal[['class_probW','class_riskCoef'] + new_exog_cols])\n",
    "\n",
    "# exog = sm.add_constant(df_reg_normal[['inverse_S','riskaversion'] + exog_cols])\n",
    "\n",
    "reg_result = sm.WLS(endog, exog,weights=df_reg_normal['weight']).fit()\n",
    "\n",
    "reg_result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\patsy\\util.py:672: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return _pandas_is_categorical_dtype(dt)\n",
      "d:\\Python\\lib\\site-packages\\patsy\\util.py:672: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return _pandas_is_categorical_dtype(dt)\n",
      "d:\\Python\\lib\\site-packages\\patsy\\util.py:672: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return _pandas_is_categorical_dtype(dt)\n",
      "d:\\Python\\lib\\site-packages\\patsy\\util.py:672: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return _pandas_is_categorical_dtype(dt)\n",
      "d:\\Python\\lib\\site-packages\\patsy\\util.py:672: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return _pandas_is_categorical_dtype(dt)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>WLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>inverse_S</td>    <th>  R-squared:         </th> <td>   0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>WLS</td>       <th>  Adj. R-squared:    </th> <td>   0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   117.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 17 Jan 2025</td> <th>  Prob (F-statistic):</th> <td>4.99e-62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:35:04</td>     <th>  Log-Likelihood:    </th> <td> -792.25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   737</td>      <th>  AIC:               </th> <td>   1592.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   733</td>      <th>  BIC:               </th> <td>   1611.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>    1.0483</td> <td>    0.137</td> <td>    7.634</td> <td> 0.000</td> <td>    0.779</td> <td>    1.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_probW</th>    <td>   -2.3700</td> <td>    0.564</td> <td>   -4.200</td> <td> 0.000</td> <td>   -3.478</td> <td>   -1.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_riskCoef</th> <td>    0.8116</td> <td>    0.193</td> <td>    4.205</td> <td> 0.000</td> <td>    0.433</td> <td>    1.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_temp</th>     <td>   -0.0355</td> <td>    0.017</td> <td>   -2.089</td> <td> 0.037</td> <td>   -0.069</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>205.296</td> <th>  Durbin-Watson:     </th> <td>   2.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2505.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.885</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.857</td>  <th>  Cond. No.          </th> <td>    348.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            WLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              inverse_S   R-squared:                       0.324\n",
       "Model:                            WLS   Adj. R-squared:                  0.322\n",
       "Method:                 Least Squares   F-statistic:                     117.3\n",
       "Date:                Fri, 17 Jan 2025   Prob (F-statistic):           4.99e-62\n",
       "Time:                        13:35:04   Log-Likelihood:                -792.25\n",
       "No. Observations:                 737   AIC:                             1592.\n",
       "Df Residuals:                     733   BIC:                             1611.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept          1.0483      0.137      7.634      0.000       0.779       1.318\n",
       "class_probW       -2.3700      0.564     -4.200      0.000      -3.478      -1.262\n",
       "class_riskCoef     0.8116      0.193      4.205      0.000       0.433       1.191\n",
       "class_temp        -0.0355      0.017     -2.089      0.037      -0.069      -0.002\n",
       "==============================================================================\n",
       "Omnibus:                      205.296   Durbin-Watson:                   2.021\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2505.146\n",
       "Skew:                           0.885   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.857   Cond. No.                         348.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_result = smf.wls('inverse_S ~ class_probW + class_riskCoef + class_temp', \n",
    "                     data=df_reg_normal, weights=df_reg_normal['weight'])\n",
    "\n",
    "reg_result.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\patsy\\util.py:672: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return _pandas_is_categorical_dtype(dt)\n",
      "d:\\Python\\lib\\site-packages\\patsy\\util.py:672: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return _pandas_is_categorical_dtype(dt)\n",
      "d:\\Python\\lib\\site-packages\\patsy\\util.py:672: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return _pandas_is_categorical_dtype(dt)\n",
      "d:\\Python\\lib\\site-packages\\patsy\\util.py:672: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return _pandas_is_categorical_dtype(dt)\n",
      "d:\\Python\\lib\\site-packages\\patsy\\util.py:672: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return _pandas_is_categorical_dtype(dt)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>WLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>inverse_S</td>    <th>  R-squared:         </th> <td>   0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>WLS</td>       <th>  Adj. R-squared:    </th> <td>   0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   115.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 17 Jan 2025</td> <th>  Prob (F-statistic):</th> <td>3.34e-61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:35:12</td>     <th>  Log-Likelihood:    </th> <td> -794.17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   737</td>      <th>  AIC:               </th> <td>   1596.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   733</td>      <th>  BIC:               </th> <td>   1615.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>   -0.0134</td> <td>    0.059</td> <td>   -0.228</td> <td> 0.820</td> <td>   -0.129</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_probW</th>    <td>    0.9285</td> <td>    0.196</td> <td>    4.746</td> <td> 0.000</td> <td>    0.544</td> <td>    1.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_riskCoef</th> <td>   -0.7248</td> <td>    0.203</td> <td>   -3.571</td> <td> 0.000</td> <td>   -1.123</td> <td>   -0.326</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank_temp</th>     <td>    0.8036</td> <td>    0.307</td> <td>    2.618</td> <td> 0.009</td> <td>    0.201</td> <td>    1.406</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>186.035</td> <th>  Durbin-Watson:     </th> <td>   2.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2428.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.742</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.768</td>  <th>  Cond. No.          </th> <td>    25.1</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            WLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              inverse_S   R-squared:                       0.321\n",
       "Model:                            WLS   Adj. R-squared:                  0.318\n",
       "Method:                 Least Squares   F-statistic:                     115.4\n",
       "Date:                Fri, 17 Jan 2025   Prob (F-statistic):           3.34e-61\n",
       "Time:                        13:35:12   Log-Likelihood:                -794.17\n",
       "No. Observations:                 737   AIC:                             1596.\n",
       "Df Residuals:                     733   BIC:                             1615.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "Intercept        -0.0134      0.059     -0.228      0.820      -0.129       0.102\n",
       "rank_probW        0.9285      0.196      4.746      0.000       0.544       1.313\n",
       "rank_riskCoef    -0.7248      0.203     -3.571      0.000      -1.123      -0.326\n",
       "rank_temp         0.8036      0.307      2.618      0.009       0.201       1.406\n",
       "==============================================================================\n",
       "Omnibus:                      186.035   Durbin-Watson:                   2.007\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2428.259\n",
       "Skew:                           0.742   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.768   Cond. No.                         25.1\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg_normal['rank_probW'] = df_reg_normal['class_probW'].rank(ascending=False, method='min') / len(df_reg_normal)\n",
    "df_reg_normal['rank_riskCoef'] = df_reg_normal['class_riskCoef'].rank(ascending=False, method='min') / len(df_reg_normal)\n",
    "df_reg_normal['rank_temp'] = df_reg_normal['class_temp'].rank(ascending=False, method='min') / len(df_reg_normal)\n",
    "\n",
    "reg_result = smf.wls('inverse_S ~ rank_probW + rank_riskCoef + rank_temp', \n",
    "                     data=df_reg_normal, weights=df_reg_normal['weight'])\n",
    "\n",
    "reg_result.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_temp</th>\n",
       "      <th>class_riskCoef</th>\n",
       "      <th>class_probW</th>\n",
       "      <th>missing_value</th>\n",
       "      <th>gambling</th>\n",
       "      <th>optimism</th>\n",
       "      <th>trust</th>\n",
       "      <th>numeracy</th>\n",
       "      <th>fin_literacy</th>\n",
       "      <th>fin_wealth</th>\n",
       "      <th>...</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>white</th>\n",
       "      <th>married</th>\n",
       "      <th>male</th>\n",
       "      <th>age2</th>\n",
       "      <th>age</th>\n",
       "      <th>riskaversion</th>\n",
       "      <th>inverse_S</th>\n",
       "      <th>ratio_indiv_stock</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class_temp</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872756</td>\n",
       "      <td>0.863692</td>\n",
       "      <td>-0.094160</td>\n",
       "      <td>0.010804</td>\n",
       "      <td>-0.005625</td>\n",
       "      <td>-0.071559</td>\n",
       "      <td>-0.060154</td>\n",
       "      <td>-0.041519</td>\n",
       "      <td>0.008339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042936</td>\n",
       "      <td>-0.065787</td>\n",
       "      <td>0.047961</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>-0.037183</td>\n",
       "      <td>-0.042789</td>\n",
       "      <td>-0.780209</td>\n",
       "      <td>-0.391941</td>\n",
       "      <td>-0.061012</td>\n",
       "      <td>0.007896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_riskCoef</th>\n",
       "      <td>0.872756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557175</td>\n",
       "      <td>-0.099147</td>\n",
       "      <td>0.067736</td>\n",
       "      <td>0.012682</td>\n",
       "      <td>-0.092160</td>\n",
       "      <td>-0.052590</td>\n",
       "      <td>-0.013498</td>\n",
       "      <td>-0.007710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050650</td>\n",
       "      <td>-0.074260</td>\n",
       "      <td>0.056668</td>\n",
       "      <td>0.020040</td>\n",
       "      <td>-0.105655</td>\n",
       "      <td>-0.106473</td>\n",
       "      <td>-0.867442</td>\n",
       "      <td>-0.145534</td>\n",
       "      <td>-0.046742</td>\n",
       "      <td>0.003155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_probW</th>\n",
       "      <td>0.863692</td>\n",
       "      <td>0.557175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.094818</td>\n",
       "      <td>-0.026231</td>\n",
       "      <td>-0.026722</td>\n",
       "      <td>-0.055904</td>\n",
       "      <td>-0.042523</td>\n",
       "      <td>-0.046612</td>\n",
       "      <td>0.017776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017442</td>\n",
       "      <td>-0.031412</td>\n",
       "      <td>0.035107</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>0.034428</td>\n",
       "      <td>0.027828</td>\n",
       "      <td>-0.487003</td>\n",
       "      <td>-0.537369</td>\n",
       "      <td>-0.071009</td>\n",
       "      <td>0.009188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_value</th>\n",
       "      <td>-0.094160</td>\n",
       "      <td>-0.099147</td>\n",
       "      <td>-0.094818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.057053</td>\n",
       "      <td>-0.039674</td>\n",
       "      <td>0.159738</td>\n",
       "      <td>-0.003673</td>\n",
       "      <td>-0.015335</td>\n",
       "      <td>-0.015549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022280</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>-0.210510</td>\n",
       "      <td>-0.012679</td>\n",
       "      <td>0.372226</td>\n",
       "      <td>0.348798</td>\n",
       "      <td>0.071621</td>\n",
       "      <td>-0.001285</td>\n",
       "      <td>0.030227</td>\n",
       "      <td>-0.007133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gambling</th>\n",
       "      <td>0.010804</td>\n",
       "      <td>0.067736</td>\n",
       "      <td>-0.026231</td>\n",
       "      <td>-0.057053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026884</td>\n",
       "      <td>0.051526</td>\n",
       "      <td>0.008562</td>\n",
       "      <td>-0.063067</td>\n",
       "      <td>-0.026790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063158</td>\n",
       "      <td>-0.039927</td>\n",
       "      <td>0.113847</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>-0.119432</td>\n",
       "      <td>-0.113259</td>\n",
       "      <td>-0.031900</td>\n",
       "      <td>0.050958</td>\n",
       "      <td>0.072094</td>\n",
       "      <td>0.053782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimism</th>\n",
       "      <td>-0.005625</td>\n",
       "      <td>0.012682</td>\n",
       "      <td>-0.026722</td>\n",
       "      <td>-0.039674</td>\n",
       "      <td>-0.026884</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.064603</td>\n",
       "      <td>0.042626</td>\n",
       "      <td>0.055704</td>\n",
       "      <td>-0.016684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>-0.182211</td>\n",
       "      <td>-0.026336</td>\n",
       "      <td>0.136648</td>\n",
       "      <td>-0.125265</td>\n",
       "      <td>-0.137464</td>\n",
       "      <td>0.015452</td>\n",
       "      <td>0.046454</td>\n",
       "      <td>-0.007182</td>\n",
       "      <td>0.119330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trust</th>\n",
       "      <td>-0.071559</td>\n",
       "      <td>-0.092160</td>\n",
       "      <td>-0.055904</td>\n",
       "      <td>0.159738</td>\n",
       "      <td>0.051526</td>\n",
       "      <td>-0.064603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.081529</td>\n",
       "      <td>-0.076617</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070642</td>\n",
       "      <td>-0.088521</td>\n",
       "      <td>-0.098554</td>\n",
       "      <td>0.035680</td>\n",
       "      <td>0.069938</td>\n",
       "      <td>0.063577</td>\n",
       "      <td>0.051961</td>\n",
       "      <td>0.027545</td>\n",
       "      <td>0.029433</td>\n",
       "      <td>0.016858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numeracy</th>\n",
       "      <td>-0.060154</td>\n",
       "      <td>-0.052590</td>\n",
       "      <td>-0.042523</td>\n",
       "      <td>-0.003673</td>\n",
       "      <td>0.008562</td>\n",
       "      <td>0.042626</td>\n",
       "      <td>-0.081529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006260</td>\n",
       "      <td>0.010658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>0.050740</td>\n",
       "      <td>0.045591</td>\n",
       "      <td>0.067777</td>\n",
       "      <td>-0.066633</td>\n",
       "      <td>-0.060889</td>\n",
       "      <td>0.044220</td>\n",
       "      <td>0.034955</td>\n",
       "      <td>0.073253</td>\n",
       "      <td>-0.010454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fin_literacy</th>\n",
       "      <td>-0.041519</td>\n",
       "      <td>-0.013498</td>\n",
       "      <td>-0.046612</td>\n",
       "      <td>-0.015335</td>\n",
       "      <td>-0.063067</td>\n",
       "      <td>0.055704</td>\n",
       "      <td>-0.076617</td>\n",
       "      <td>-0.006260</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019818</td>\n",
       "      <td>0.014896</td>\n",
       "      <td>0.050014</td>\n",
       "      <td>0.075788</td>\n",
       "      <td>0.012782</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>0.052496</td>\n",
       "      <td>0.046886</td>\n",
       "      <td>-0.039292</td>\n",
       "      <td>0.004658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fin_wealth</th>\n",
       "      <td>0.008339</td>\n",
       "      <td>-0.007710</td>\n",
       "      <td>0.017776</td>\n",
       "      <td>-0.015549</td>\n",
       "      <td>-0.026790</td>\n",
       "      <td>-0.016684</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>0.010658</td>\n",
       "      <td>0.018225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041285</td>\n",
       "      <td>0.042535</td>\n",
       "      <td>0.069851</td>\n",
       "      <td>-0.034468</td>\n",
       "      <td>0.064235</td>\n",
       "      <td>0.070636</td>\n",
       "      <td>-0.019286</td>\n",
       "      <td>-0.027961</td>\n",
       "      <td>-0.088871</td>\n",
       "      <td>0.041185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>familyincome_value</th>\n",
       "      <td>0.085949</td>\n",
       "      <td>0.113103</td>\n",
       "      <td>0.062740</td>\n",
       "      <td>-0.458740</td>\n",
       "      <td>0.080072</td>\n",
       "      <td>0.019185</td>\n",
       "      <td>-0.204791</td>\n",
       "      <td>-0.008811</td>\n",
       "      <td>0.082994</td>\n",
       "      <td>0.133101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029476</td>\n",
       "      <td>0.039718</td>\n",
       "      <td>0.417931</td>\n",
       "      <td>0.083953</td>\n",
       "      <td>-0.156177</td>\n",
       "      <td>-0.142534</td>\n",
       "      <td>-0.075296</td>\n",
       "      <td>-0.008027</td>\n",
       "      <td>-0.013023</td>\n",
       "      <td>-0.021465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>master_degree</th>\n",
       "      <td>-0.024073</td>\n",
       "      <td>-0.020485</td>\n",
       "      <td>-0.018027</td>\n",
       "      <td>-0.157421</td>\n",
       "      <td>-0.123172</td>\n",
       "      <td>0.032176</td>\n",
       "      <td>-0.160247</td>\n",
       "      <td>0.047762</td>\n",
       "      <td>0.043982</td>\n",
       "      <td>0.022681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034759</td>\n",
       "      <td>0.026603</td>\n",
       "      <td>0.032490</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.082705</td>\n",
       "      <td>0.085863</td>\n",
       "      <td>0.022128</td>\n",
       "      <td>-0.008154</td>\n",
       "      <td>-0.119249</td>\n",
       "      <td>-0.152369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bachelor_degree</th>\n",
       "      <td>0.026709</td>\n",
       "      <td>0.031480</td>\n",
       "      <td>0.015777</td>\n",
       "      <td>0.097341</td>\n",
       "      <td>0.044473</td>\n",
       "      <td>-0.007954</td>\n",
       "      <td>0.029262</td>\n",
       "      <td>-0.030732</td>\n",
       "      <td>0.028305</td>\n",
       "      <td>-0.014445</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034326</td>\n",
       "      <td>-0.065831</td>\n",
       "      <td>-0.019699</td>\n",
       "      <td>0.053727</td>\n",
       "      <td>-0.099056</td>\n",
       "      <td>-0.099073</td>\n",
       "      <td>-0.034435</td>\n",
       "      <td>-0.023636</td>\n",
       "      <td>0.065925</td>\n",
       "      <td>-0.104970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_college_degree</th>\n",
       "      <td>-0.004093</td>\n",
       "      <td>-0.014061</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.066688</td>\n",
       "      <td>0.090484</td>\n",
       "      <td>-0.028066</td>\n",
       "      <td>0.152285</td>\n",
       "      <td>-0.018785</td>\n",
       "      <td>-0.085716</td>\n",
       "      <td>-0.009100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082194</td>\n",
       "      <td>0.048417</td>\n",
       "      <td>-0.014237</td>\n",
       "      <td>-0.066922</td>\n",
       "      <td>0.022880</td>\n",
       "      <td>0.019201</td>\n",
       "      <td>0.015709</td>\n",
       "      <td>0.038118</td>\n",
       "      <td>0.059960</td>\n",
       "      <td>0.305306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>householdmembers</th>\n",
       "      <td>0.072191</td>\n",
       "      <td>0.095975</td>\n",
       "      <td>0.036035</td>\n",
       "      <td>-0.175624</td>\n",
       "      <td>0.075245</td>\n",
       "      <td>0.034795</td>\n",
       "      <td>-0.053277</td>\n",
       "      <td>0.037014</td>\n",
       "      <td>0.043547</td>\n",
       "      <td>-0.040101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112396</td>\n",
       "      <td>-0.114456</td>\n",
       "      <td>0.073997</td>\n",
       "      <td>-0.015953</td>\n",
       "      <td>-0.427389</td>\n",
       "      <td>-0.437063</td>\n",
       "      <td>-0.070593</td>\n",
       "      <td>-0.009932</td>\n",
       "      <td>0.017270</td>\n",
       "      <td>0.270922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employed</th>\n",
       "      <td>0.038296</td>\n",
       "      <td>0.066706</td>\n",
       "      <td>0.017446</td>\n",
       "      <td>-0.658320</td>\n",
       "      <td>0.059553</td>\n",
       "      <td>0.033973</td>\n",
       "      <td>-0.074213</td>\n",
       "      <td>0.029986</td>\n",
       "      <td>0.027113</td>\n",
       "      <td>-0.047888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050570</td>\n",
       "      <td>-0.094618</td>\n",
       "      <td>0.029417</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>-0.551400</td>\n",
       "      <td>-0.525263</td>\n",
       "      <td>-0.057635</td>\n",
       "      <td>0.051953</td>\n",
       "      <td>-0.014646</td>\n",
       "      <td>0.056261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hispanic</th>\n",
       "      <td>0.042936</td>\n",
       "      <td>0.050650</td>\n",
       "      <td>0.017442</td>\n",
       "      <td>-0.022280</td>\n",
       "      <td>0.063158</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>0.070642</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>0.019818</td>\n",
       "      <td>-0.041285</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.191969</td>\n",
       "      <td>-0.020746</td>\n",
       "      <td>0.023125</td>\n",
       "      <td>-0.208709</td>\n",
       "      <td>-0.233973</td>\n",
       "      <td>-0.018720</td>\n",
       "      <td>-0.013411</td>\n",
       "      <td>-0.009714</td>\n",
       "      <td>0.085064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>-0.065787</td>\n",
       "      <td>-0.074260</td>\n",
       "      <td>-0.031412</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>-0.039927</td>\n",
       "      <td>-0.182211</td>\n",
       "      <td>-0.088521</td>\n",
       "      <td>0.050740</td>\n",
       "      <td>0.014896</td>\n",
       "      <td>0.042535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059848</td>\n",
       "      <td>0.037542</td>\n",
       "      <td>0.204708</td>\n",
       "      <td>0.206367</td>\n",
       "      <td>0.046682</td>\n",
       "      <td>0.013298</td>\n",
       "      <td>-0.018132</td>\n",
       "      <td>-0.010056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>married</th>\n",
       "      <td>0.047961</td>\n",
       "      <td>0.056668</td>\n",
       "      <td>0.035107</td>\n",
       "      <td>-0.210510</td>\n",
       "      <td>0.113847</td>\n",
       "      <td>-0.026336</td>\n",
       "      <td>-0.098554</td>\n",
       "      <td>0.045591</td>\n",
       "      <td>0.050014</td>\n",
       "      <td>0.069851</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020746</td>\n",
       "      <td>0.059848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.121985</td>\n",
       "      <td>-0.085932</td>\n",
       "      <td>-0.063146</td>\n",
       "      <td>-0.073593</td>\n",
       "      <td>0.028361</td>\n",
       "      <td>0.047237</td>\n",
       "      <td>-0.031185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.020040</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>-0.012679</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.136648</td>\n",
       "      <td>0.035680</td>\n",
       "      <td>0.067777</td>\n",
       "      <td>0.075788</td>\n",
       "      <td>-0.034468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023125</td>\n",
       "      <td>0.037542</td>\n",
       "      <td>0.121985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013018</td>\n",
       "      <td>0.008291</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.097774</td>\n",
       "      <td>0.041134</td>\n",
       "      <td>0.043834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age2</th>\n",
       "      <td>-0.037183</td>\n",
       "      <td>-0.105655</td>\n",
       "      <td>0.034428</td>\n",
       "      <td>0.372226</td>\n",
       "      <td>-0.119432</td>\n",
       "      <td>-0.125265</td>\n",
       "      <td>0.069938</td>\n",
       "      <td>-0.066633</td>\n",
       "      <td>0.012782</td>\n",
       "      <td>0.064235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208709</td>\n",
       "      <td>0.204708</td>\n",
       "      <td>-0.085932</td>\n",
       "      <td>0.013018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988342</td>\n",
       "      <td>0.084957</td>\n",
       "      <td>-0.040326</td>\n",
       "      <td>-0.016958</td>\n",
       "      <td>-0.311695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.042789</td>\n",
       "      <td>-0.106473</td>\n",
       "      <td>0.027828</td>\n",
       "      <td>0.348798</td>\n",
       "      <td>-0.113259</td>\n",
       "      <td>-0.137464</td>\n",
       "      <td>0.063577</td>\n",
       "      <td>-0.060889</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>0.070636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233973</td>\n",
       "      <td>0.206367</td>\n",
       "      <td>-0.063146</td>\n",
       "      <td>0.008291</td>\n",
       "      <td>0.988342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>-0.031863</td>\n",
       "      <td>-0.018636</td>\n",
       "      <td>-0.369312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>riskaversion</th>\n",
       "      <td>-0.780209</td>\n",
       "      <td>-0.867442</td>\n",
       "      <td>-0.487003</td>\n",
       "      <td>0.071621</td>\n",
       "      <td>-0.031900</td>\n",
       "      <td>0.015452</td>\n",
       "      <td>0.051961</td>\n",
       "      <td>0.044220</td>\n",
       "      <td>0.052496</td>\n",
       "      <td>-0.019286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018720</td>\n",
       "      <td>0.046682</td>\n",
       "      <td>-0.073593</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.084957</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.153718</td>\n",
       "      <td>0.054625</td>\n",
       "      <td>-0.015253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inverse_S</th>\n",
       "      <td>-0.391941</td>\n",
       "      <td>-0.145534</td>\n",
       "      <td>-0.537369</td>\n",
       "      <td>-0.001285</td>\n",
       "      <td>0.050958</td>\n",
       "      <td>0.046454</td>\n",
       "      <td>0.027545</td>\n",
       "      <td>0.034955</td>\n",
       "      <td>0.046886</td>\n",
       "      <td>-0.027961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013411</td>\n",
       "      <td>0.013298</td>\n",
       "      <td>0.028361</td>\n",
       "      <td>0.097774</td>\n",
       "      <td>-0.040326</td>\n",
       "      <td>-0.031863</td>\n",
       "      <td>0.153718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042016</td>\n",
       "      <td>-0.044021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_indiv_stock</th>\n",
       "      <td>-0.061012</td>\n",
       "      <td>-0.046742</td>\n",
       "      <td>-0.071009</td>\n",
       "      <td>0.030227</td>\n",
       "      <td>0.072094</td>\n",
       "      <td>-0.007182</td>\n",
       "      <td>0.029433</td>\n",
       "      <td>0.073253</td>\n",
       "      <td>-0.039292</td>\n",
       "      <td>-0.088871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009714</td>\n",
       "      <td>-0.018132</td>\n",
       "      <td>0.047237</td>\n",
       "      <td>0.041134</td>\n",
       "      <td>-0.016958</td>\n",
       "      <td>-0.018636</td>\n",
       "      <td>0.054625</td>\n",
       "      <td>0.042016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>0.007896</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>0.009188</td>\n",
       "      <td>-0.007133</td>\n",
       "      <td>0.053782</td>\n",
       "      <td>0.119330</td>\n",
       "      <td>0.016858</td>\n",
       "      <td>-0.010454</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.041185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085064</td>\n",
       "      <td>-0.010056</td>\n",
       "      <td>-0.031185</td>\n",
       "      <td>0.043834</td>\n",
       "      <td>-0.311695</td>\n",
       "      <td>-0.369312</td>\n",
       "      <td>-0.015253</td>\n",
       "      <td>-0.044021</td>\n",
       "      <td>-0.005884</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    class_temp  class_riskCoef  class_probW  missing_value  \\\n",
       "class_temp            1.000000        0.872756     0.863692      -0.094160   \n",
       "class_riskCoef        0.872756        1.000000     0.557175      -0.099147   \n",
       "class_probW           0.863692        0.557175     1.000000      -0.094818   \n",
       "missing_value        -0.094160       -0.099147    -0.094818       1.000000   \n",
       "gambling              0.010804        0.067736    -0.026231      -0.057053   \n",
       "optimism             -0.005625        0.012682    -0.026722      -0.039674   \n",
       "trust                -0.071559       -0.092160    -0.055904       0.159738   \n",
       "numeracy             -0.060154       -0.052590    -0.042523      -0.003673   \n",
       "fin_literacy         -0.041519       -0.013498    -0.046612      -0.015335   \n",
       "fin_wealth            0.008339       -0.007710     0.017776      -0.015549   \n",
       "familyincome_value    0.085949        0.113103     0.062740      -0.458740   \n",
       "master_degree        -0.024073       -0.020485    -0.018027      -0.157421   \n",
       "bachelor_degree       0.026709        0.031480     0.015777       0.097341   \n",
       "no_college_degree    -0.004093       -0.014061     0.002041       0.066688   \n",
       "householdmembers      0.072191        0.095975     0.036035      -0.175624   \n",
       "employed              0.038296        0.066706     0.017446      -0.658320   \n",
       "hispanic              0.042936        0.050650     0.017442      -0.022280   \n",
       "white                -0.065787       -0.074260    -0.031412       0.000129   \n",
       "married               0.047961        0.056668     0.035107      -0.210510   \n",
       "male                  0.002696        0.020040     0.006366      -0.012679   \n",
       "age2                 -0.037183       -0.105655     0.034428       0.372226   \n",
       "age                  -0.042789       -0.106473     0.027828       0.348798   \n",
       "riskaversion         -0.780209       -0.867442    -0.487003       0.071621   \n",
       "inverse_S            -0.391941       -0.145534    -0.537369      -0.001285   \n",
       "ratio_indiv_stock    -0.061012       -0.046742    -0.071009       0.030227   \n",
       "weight                0.007896        0.003155     0.009188      -0.007133   \n",
       "\n",
       "                    gambling  optimism     trust  numeracy  fin_literacy  \\\n",
       "class_temp          0.010804 -0.005625 -0.071559 -0.060154     -0.041519   \n",
       "class_riskCoef      0.067736  0.012682 -0.092160 -0.052590     -0.013498   \n",
       "class_probW        -0.026231 -0.026722 -0.055904 -0.042523     -0.046612   \n",
       "missing_value      -0.057053 -0.039674  0.159738 -0.003673     -0.015335   \n",
       "gambling            1.000000 -0.026884  0.051526  0.008562     -0.063067   \n",
       "optimism           -0.026884  1.000000 -0.064603  0.042626      0.055704   \n",
       "trust               0.051526 -0.064603  1.000000 -0.081529     -0.076617   \n",
       "numeracy            0.008562  0.042626 -0.081529  1.000000     -0.006260   \n",
       "fin_literacy       -0.063067  0.055704 -0.076617 -0.006260      1.000000   \n",
       "fin_wealth         -0.026790 -0.016684  0.043519  0.010658      0.018225   \n",
       "familyincome_value  0.080072  0.019185 -0.204791 -0.008811      0.082994   \n",
       "master_degree      -0.123172  0.032176 -0.160247  0.047762      0.043982   \n",
       "bachelor_degree     0.044473 -0.007954  0.029262 -0.030732      0.028305   \n",
       "no_college_degree   0.090484 -0.028066  0.152285 -0.018785     -0.085716   \n",
       "householdmembers    0.075245  0.034795 -0.053277  0.037014      0.043547   \n",
       "employed            0.059553  0.033973 -0.074213  0.029986      0.027113   \n",
       "hispanic            0.063158  0.031189  0.070642  0.012939      0.019818   \n",
       "white              -0.039927 -0.182211 -0.088521  0.050740      0.014896   \n",
       "married             0.113847 -0.026336 -0.098554  0.045591      0.050014   \n",
       "male                0.068966  0.136648  0.035680  0.067777      0.075788   \n",
       "age2               -0.119432 -0.125265  0.069938 -0.066633      0.012782   \n",
       "age                -0.113259 -0.137464  0.063577 -0.060889      0.014851   \n",
       "riskaversion       -0.031900  0.015452  0.051961  0.044220      0.052496   \n",
       "inverse_S           0.050958  0.046454  0.027545  0.034955      0.046886   \n",
       "ratio_indiv_stock   0.072094 -0.007182  0.029433  0.073253     -0.039292   \n",
       "weight              0.053782  0.119330  0.016858 -0.010454      0.004658   \n",
       "\n",
       "                    fin_wealth  ...  hispanic     white   married      male  \\\n",
       "class_temp            0.008339  ...  0.042936 -0.065787  0.047961  0.002696   \n",
       "class_riskCoef       -0.007710  ...  0.050650 -0.074260  0.056668  0.020040   \n",
       "class_probW           0.017776  ...  0.017442 -0.031412  0.035107  0.006366   \n",
       "missing_value        -0.015549  ... -0.022280  0.000129 -0.210510 -0.012679   \n",
       "gambling             -0.026790  ...  0.063158 -0.039927  0.113847  0.068966   \n",
       "optimism             -0.016684  ...  0.031189 -0.182211 -0.026336  0.136648   \n",
       "trust                 0.043519  ...  0.070642 -0.088521 -0.098554  0.035680   \n",
       "numeracy              0.010658  ...  0.012939  0.050740  0.045591  0.067777   \n",
       "fin_literacy          0.018225  ...  0.019818  0.014896  0.050014  0.075788   \n",
       "fin_wealth            1.000000  ... -0.041285  0.042535  0.069851 -0.034468   \n",
       "familyincome_value    0.133101  ... -0.029476  0.039718  0.417931  0.083953   \n",
       "master_degree         0.022681  ... -0.034759  0.026603  0.032490  0.001692   \n",
       "bachelor_degree      -0.014445  ... -0.034326 -0.065831 -0.019699  0.053727   \n",
       "no_college_degree    -0.009100  ...  0.082194  0.048417 -0.014237 -0.066922   \n",
       "householdmembers     -0.040101  ...  0.112396 -0.114456  0.073997 -0.015953   \n",
       "employed             -0.047888  ...  0.050570 -0.094618  0.029417  0.001838   \n",
       "hispanic             -0.041285  ...  1.000000 -0.191969 -0.020746  0.023125   \n",
       "white                 0.042535  ... -0.191969  1.000000  0.059848  0.037542   \n",
       "married               0.069851  ... -0.020746  0.059848  1.000000  0.121985   \n",
       "male                 -0.034468  ...  0.023125  0.037542  0.121985  1.000000   \n",
       "age2                  0.064235  ... -0.208709  0.204708 -0.085932  0.013018   \n",
       "age                   0.070636  ... -0.233973  0.206367 -0.063146  0.008291   \n",
       "riskaversion         -0.019286  ... -0.018720  0.046682 -0.073593  0.007381   \n",
       "inverse_S            -0.027961  ... -0.013411  0.013298  0.028361  0.097774   \n",
       "ratio_indiv_stock    -0.088871  ... -0.009714 -0.018132  0.047237  0.041134   \n",
       "weight                0.041185  ...  0.085064 -0.010056 -0.031185  0.043834   \n",
       "\n",
       "                        age2       age  riskaversion  inverse_S  \\\n",
       "class_temp         -0.037183 -0.042789     -0.780209  -0.391941   \n",
       "class_riskCoef     -0.105655 -0.106473     -0.867442  -0.145534   \n",
       "class_probW         0.034428  0.027828     -0.487003  -0.537369   \n",
       "missing_value       0.372226  0.348798      0.071621  -0.001285   \n",
       "gambling           -0.119432 -0.113259     -0.031900   0.050958   \n",
       "optimism           -0.125265 -0.137464      0.015452   0.046454   \n",
       "trust               0.069938  0.063577      0.051961   0.027545   \n",
       "numeracy           -0.066633 -0.060889      0.044220   0.034955   \n",
       "fin_literacy        0.012782  0.014851      0.052496   0.046886   \n",
       "fin_wealth          0.064235  0.070636     -0.019286  -0.027961   \n",
       "familyincome_value -0.156177 -0.142534     -0.075296  -0.008027   \n",
       "master_degree       0.082705  0.085863      0.022128  -0.008154   \n",
       "bachelor_degree    -0.099056 -0.099073     -0.034435  -0.023636   \n",
       "no_college_degree   0.022880  0.019201      0.015709   0.038118   \n",
       "householdmembers   -0.427389 -0.437063     -0.070593  -0.009932   \n",
       "employed           -0.551400 -0.525263     -0.057635   0.051953   \n",
       "hispanic           -0.208709 -0.233973     -0.018720  -0.013411   \n",
       "white               0.204708  0.206367      0.046682   0.013298   \n",
       "married            -0.085932 -0.063146     -0.073593   0.028361   \n",
       "male                0.013018  0.008291      0.007381   0.097774   \n",
       "age2                1.000000  0.988342      0.084957  -0.040326   \n",
       "age                 0.988342  1.000000      0.085455  -0.031863   \n",
       "riskaversion        0.084957  0.085455      1.000000   0.153718   \n",
       "inverse_S          -0.040326 -0.031863      0.153718   1.000000   \n",
       "ratio_indiv_stock  -0.016958 -0.018636      0.054625   0.042016   \n",
       "weight             -0.311695 -0.369312     -0.015253  -0.044021   \n",
       "\n",
       "                    ratio_indiv_stock    weight  \n",
       "class_temp                  -0.061012  0.007896  \n",
       "class_riskCoef              -0.046742  0.003155  \n",
       "class_probW                 -0.071009  0.009188  \n",
       "missing_value                0.030227 -0.007133  \n",
       "gambling                     0.072094  0.053782  \n",
       "optimism                    -0.007182  0.119330  \n",
       "trust                        0.029433  0.016858  \n",
       "numeracy                     0.073253 -0.010454  \n",
       "fin_literacy                -0.039292  0.004658  \n",
       "fin_wealth                  -0.088871  0.041185  \n",
       "familyincome_value          -0.013023 -0.021465  \n",
       "master_degree               -0.119249 -0.152369  \n",
       "bachelor_degree              0.065925 -0.104970  \n",
       "no_college_degree            0.059960  0.305306  \n",
       "householdmembers             0.017270  0.270922  \n",
       "employed                    -0.014646  0.056261  \n",
       "hispanic                    -0.009714  0.085064  \n",
       "white                       -0.018132 -0.010056  \n",
       "married                      0.047237 -0.031185  \n",
       "male                         0.041134  0.043834  \n",
       "age2                        -0.016958 -0.311695  \n",
       "age                         -0.018636 -0.369312  \n",
       "riskaversion                 0.054625 -0.015253  \n",
       "inverse_S                    0.042016 -0.044021  \n",
       "ratio_indiv_stock            1.000000 -0.005884  \n",
       "weight                      -0.005884  1.000000  \n",
       "\n",
       "[26 rows x 26 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg_normal.iloc[:, ::-1].corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 53.,  12.,  15., 150., 230.,  56.,  29.,  30.,  13.,   9.,  15.,\n",
       "         10.,   7.,   5.,  11.,   5.,   7.,   6.,   5.,   8.,   3.,   4.,\n",
       "          3.,   2.,   1.,   4.,   8.,   2.,   6.,  28.]),\n",
       " array([1.88127999e-07, 3.06760323e-02, 6.13518765e-02, 9.20277206e-02,\n",
       "        1.22703565e-01, 1.53379409e-01, 1.84055253e-01, 2.14731097e-01,\n",
       "        2.45406941e-01, 2.76082786e-01, 3.06758630e-01, 3.37434474e-01,\n",
       "        3.68110318e-01, 3.98786162e-01, 4.29462007e-01, 4.60137851e-01,\n",
       "        4.90813695e-01, 5.21489539e-01, 5.52165383e-01, 5.82841227e-01,\n",
       "        6.13517072e-01, 6.44192916e-01, 6.74868760e-01, 7.05544604e-01,\n",
       "        7.36220448e-01, 7.66896292e-01, 7.97572137e-01, 8.28247981e-01,\n",
       "        8.58923825e-01, 8.89599669e-01, 9.20275513e-01]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_equity['class_probW'],bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 10.,  16.,  34., 198.,  19.,  13.,   8.,   6.,  10.,   6.,   2.,\n",
       "          8.,   5.,   9.,   4.,   5.,   5.,   4.,   2.,   8.,   7.,   6.,\n",
       "          7.,   7.,   7.,  16.,  16.,  18.,  70., 211.]),\n",
       " array([0.04714923, 0.07891093, 0.11067262, 0.14243431, 0.174196  ,\n",
       "        0.20595769, 0.23771938, 0.26948107, 0.30124276, 0.33300445,\n",
       "        0.36476614, 0.39652783, 0.42828952, 0.46005122, 0.49181291,\n",
       "        0.5235746 , 0.55533629, 0.58709798, 0.61885967, 0.65062136,\n",
       "        0.68238305, 0.71414474, 0.74590643, 0.77766812, 0.80942981,\n",
       "        0.84119151, 0.8729532 , 0.90471489, 0.93647658, 0.96823827,\n",
       "        0.99999996]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_equity['class_riskCoef'],bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([275.,  22.,  53.,  24.,  16.,  13.,  10.,  10.,  12.,  15.,  12.,\n",
       "         29.,  82.,  20.,  18.,  10.,   3.,   8.,  10.,   7.,   7.,   7.,\n",
       "          4.,   4.,   1.,   6.,   5.,   8.,  12.,  34.]),\n",
       " array([ 0.44257511,  0.99525017,  1.54792523,  2.10060028,  2.65327534,\n",
       "         3.2059504 ,  3.75862546,  4.31130051,  4.86397557,  5.41665063,\n",
       "         5.96932569,  6.52200074,  7.0746758 ,  7.62735086,  8.18002592,\n",
       "         8.73270098,  9.28537603,  9.83805109, 10.39072615, 10.94340121,\n",
       "        11.49607626, 12.04875132, 12.60142638, 13.15410144, 13.70677649,\n",
       "        14.25945155, 14.81212661, 15.36480167, 15.91747672, 16.47015178,\n",
       "        17.02282684]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAGdCAYAAADey0OaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhOUlEQVR4nO3dfVCVdf7/8Reo4M1yDoMKB1bEm827VHJNie7WTUZA1nRyt3Td0tbVXQeaNboxdkqzdpayppoc03YmtabMaiZ10tYWUbEbtEIdbypGHfJm9EDpwPFmRYTr+8fv55mOAnYQhPfh+Zg5M3Kuz3XxuS4uDk+vcw6EOY7jCAAAoI0Lb+0JAAAA/BxECwAAMIFoAQAAJhAtAADABKIFAACYQLQAAAATiBYAAGAC0QIAAEzo2NoTaIq6ujodP35cUVFRCgsLa+3pAACAn8FxHJ0+fVoJCQkKDw/+uonJaDl+/LgSExNbexoAAKAJjh49ql69egW9nsloiYqKkvT/dtrlcrXybAAAwM/h8/mUmJjo/zkeLJPRcukpIZfLRbQAAGBMU1/awQtxAQCACUQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABM6tvYE2qI+T2xo8rrfP5fVjDMBAACXcKUFAACYQLQAAAATiBYAAGAC0QIAAEwgWgAAgAlECwAAMIFoAQAAJhAtAADABKIFAACYQLQAAAATiBYAAGAC0QIAAEwgWgAAgAlECwAAMIFoAQAAJhAtAADABKIFAACYQLQAAAATiBYAAGAC0QIAAEwgWgAAgAlECwAAMIFoAQAAJhAtAADABKIFAACYQLQAAAATiBYAAGBCUNGSn5+vUaNGKSoqSrGxsZo0aZJKS0sDxowZM0ZhYWEBt7/97W8BY44cOaKsrCx17dpVsbGxeuyxx3Tx4sVr3xsAABCyOgYzuKioSNnZ2Ro1apQuXryof/zjHxo3bpy++eYbdevWzT9u1qxZeuaZZ/wfd+3a1f/v2tpaZWVlyePx6IsvvtCJEyf0wAMPqFOnTvrXv/7VDLsEAABCUVDRsnHjxoCPV65cqdjYWJWUlOjOO+/039+1a1d5PJ56t/Hf//5X33zzjTZt2qS4uDjddNNNevbZZzVv3jw9/fTTioiIaMJuAACAUHdNr2mpqqqSJMXExATc/84776hHjx4aOnSo8vLydO7cOf+y4uJiDRs2THFxcf770tPT5fP5tH///no/T3V1tXw+X8ANAAC0L0Fdafmpuro6zZ07V7fddpuGDh3qv/+Pf/yjkpKSlJCQoD179mjevHkqLS3Vhx9+KEnyer0BwSLJ/7HX6633c+Xn52vhwoVNnSoAAAgBTY6W7Oxs7du3T5999lnA/bNnz/b/e9iwYYqPj9fYsWN16NAh9e/fv0mfKy8vT7m5uf6PfT6fEhMTmzZxAABgUpOeHsrJydH69eu1ZcsW9erVq9GxKSkpkqSDBw9Kkjwej8rLywPGXPq4odfBREZGyuVyBdwAAED7ElS0OI6jnJwcrVmzRps3b1bfvn2vus7u3bslSfHx8ZKk1NRU7d27VxUVFf4xBQUFcrlcGjJkSDDTAQAA7UhQTw9lZ2dr1apVWrdunaKiovyvQXG73erSpYsOHTqkVatWafz48erevbv27Nmjhx9+WHfeeaeGDx8uSRo3bpyGDBmi+++/X4sWLZLX69WTTz6p7OxsRUZGNv8eAgCAkBDUlZalS5eqqqpKY8aMUXx8vP/23nvvSZIiIiK0adMmjRs3ToMGDdIjjzyiyZMn66OPPvJvo0OHDlq/fr06dOig1NRU/elPf9IDDzwQ8HtdAAAALhfUlRbHcRpdnpiYqKKioqtuJykpSR9//HEwnxoAALRz/O0hAABgAtECAABMIFoAAIAJRAsAADCBaAEAACYQLQAAwASiBQAAmEC0AAAAE4gWAABgAtECAABMIFoAAIAJRAsAADCBaAEAACYQLQAAwASiBQAAmEC0AAAAE4gWAABgAtECAABMIFoAAIAJRAsAADCBaAEAACYQLQAAwASiBQAAmEC0AAAAE4gWAABgAtECAABMIFoAAIAJRAsAADCBaAEAACYQLQAAwASiBQAAmEC0AAAAE4gWAABgAtECAABMIFoAAIAJRAsAADCBaAEAACYQLQAAwASiBQAAmEC0AAAAE4gWAABgAtECAABMIFoAAIAJRAsAADCBaAEAACYQLQAAwASiBQAAmEC0AAAAE4gWAABgAtECAABMIFoAAIAJRAsAADCBaAEAACYEFS35+fkaNWqUoqKiFBsbq0mTJqm0tDRgzPnz55Wdna3u3bvrF7/4hSZPnqzy8vKAMUeOHFFWVpa6du2q2NhYPfbYY7p48eK17w0AAAhZQUVLUVGRsrOztX37dhUUFKimpkbjxo3T2bNn/WMefvhhffTRR/rggw9UVFSk48eP65577vEvr62tVVZWli5cuKAvvvhCb775plauXKn58+c3314BAICQE+Y4jtPUlX/44QfFxsaqqKhId955p6qqqtSzZ0+tWrVKv//97yVJ3333nQYPHqzi4mLdcsst+s9//qPf/e53On78uOLi4iRJy5Yt07x58/TDDz8oIiLiqp/X5/PJ7XarqqpKLperqdNvUJ8nNjR53e+fy2rGmQAAEDqu9ef3Nb2mpaqqSpIUExMjSSopKVFNTY3S0tL8YwYNGqTevXuruLhYklRcXKxhw4b5g0WS0tPT5fP5tH///no/T3V1tXw+X8ANAAC0L02Olrq6Os2dO1e33Xabhg4dKknyer2KiIhQdHR0wNi4uDh5vV7/mJ8Gy6Xll5bVJz8/X263239LTExs6rQBAIBRTY6W7Oxs7du3T6tXr27O+dQrLy9PVVVV/tvRo0db/HMCAIC2pWNTVsrJydH69eu1bds29erVy3+/x+PRhQsXVFlZGXC1pby8XB6Pxz/myy+/DNjepXcXXRpzucjISEVGRjZlqgAAIEQEdaXFcRzl5ORozZo12rx5s/r27RuwfOTIkerUqZMKCwv995WWlurIkSNKTU2VJKWmpmrv3r2qqKjwjykoKJDL5dKQIUOuZV8AAEAIC+pKS3Z2tlatWqV169YpKirK/xoUt9utLl26yO12a+bMmcrNzVVMTIxcLpceeughpaam6pZbbpEkjRs3TkOGDNH999+vRYsWyev16sknn1R2djZXUwAAQIOCipalS5dKksaMGRNw/4oVKzRjxgxJ0ssvv6zw8HBNnjxZ1dXVSk9P12uvveYf26FDB61fv15z5sxRamqqunXrpunTp+uZZ565tj0BAAAh7Zp+T0tr4fe0AABgT6v+nhYAAIDrhWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOCjpZt27ZpwoQJSkhIUFhYmNauXRuwfMaMGQoLCwu4ZWRkBIw5deqUpk2bJpfLpejoaM2cOVNnzpy5ph0BAAChLehoOXv2rJKTk7VkyZIGx2RkZOjEiRP+27vvvhuwfNq0adq/f78KCgq0fv16bdu2TbNnzw5+9gAAoN3oGOwKmZmZyszMbHRMZGSkPB5Pvcu+/fZbbdy4UV999ZVuvvlmSdLixYs1fvx4vfjii0pISAh2SgAAoB1okde0bN26VbGxsRo4cKDmzJmjkydP+pcVFxcrOjraHyySlJaWpvDwcO3YsaPe7VVXV8vn8wXcAABA+9Ls0ZKRkaG33npLhYWFev7551VUVKTMzEzV1tZKkrxer2JjYwPW6dixo2JiYuT1euvdZn5+vtxut/+WmJjY3NMGAABtXNBPD13NlClT/P8eNmyYhg8frv79+2vr1q0aO3Zsk7aZl5en3Nxc/8c+n49wAQCgnWnxtzz369dPPXr00MGDByVJHo9HFRUVAWMuXryoU6dONfg6mMjISLlcroAbAABoX1o8Wo4dO6aTJ08qPj5ekpSamqrKykqVlJT4x2zevFl1dXVKSUlp6ekAAACjgn566MyZM/6rJpJUVlam3bt3KyYmRjExMVq4cKEmT54sj8ejQ4cO6fHHH9evfvUrpaenS5IGDx6sjIwMzZo1S8uWLVNNTY1ycnI0ZcoU3jkEAAAaFPSVlq+//lojRozQiBEjJEm5ubkaMWKE5s+frw4dOmjPnj26++67NWDAAM2cOVMjR47Up59+qsjISP823nnnHQ0aNEhjx47V+PHjdfvtt+vf//538+0VAAAIOUFfaRkzZowcx2lw+SeffHLVbcTExGjVqlXBfmoAANCO8beHAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJgQdLRs27ZNEyZMUEJCgsLCwrR27dqA5Y7jaP78+YqPj1eXLl2UlpamAwcOBIw5deqUpk2bJpfLpejoaM2cOVNnzpy5ph0BAAChLehoOXv2rJKTk7VkyZJ6ly9atEivvvqqli1bph07dqhbt25KT0/X+fPn/WOmTZum/fv3q6CgQOvXr9e2bds0e/bspu8FAAAIeR2DXSEzM1OZmZn1LnMcR6+88oqefPJJTZw4UZL01ltvKS4uTmvXrtWUKVP07bffauPGjfrqq6908803S5IWL16s8ePH68UXX1RCQsI17A4AAAhVzfqalrKyMnm9XqWlpfnvc7vdSklJUXFxsSSpuLhY0dHR/mCRpLS0NIWHh2vHjh31bre6ulo+ny/gBgAA2pdmjRav1ytJiouLC7g/Li7Ov8zr9So2NjZgeceOHRUTE+Mfc7n8/Hy53W7/LTExsTmnDQAADDDx7qG8vDxVVVX5b0ePHm3tKQEAgOusWaPF4/FIksrLywPuLy8v9y/zeDyqqKgIWH7x4kWdOnXKP+ZykZGRcrlcATcAANC+NGu09O3bVx6PR4WFhf77fD6fduzYodTUVElSamqqKisrVVJS4h+zefNm1dXVKSUlpTmnAwAAQkjQ7x46c+aMDh486P+4rKxMu3fvVkxMjHr37q25c+fqn//8p2644Qb17dtXTz31lBISEjRp0iRJ0uDBg5WRkaFZs2Zp2bJlqqmpUU5OjqZMmcI7hwAAQIOCjpavv/5av/3tb/0f5+bmSpKmT5+ulStX6vHHH9fZs2c1e/ZsVVZW6vbbb9fGjRvVuXNn/zrvvPOOcnJyNHbsWIWHh2vy5Ml69dVXm2F3AABAqApzHMdp7UkEy+fzye12q6qqqkVe39LniQ1NXvf757KacSYAAISOa/35beLdQwAAAEQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATOjY2hMA0LL6PLGhyet+/1xWM84EAK4NV1oAAIAJRAsAADCBaAEAACYQLQAAwASiBQAAmEC0AAAAE4gWAABgAtECAABMIFoAAIAJRAsAADCBaAEAACYQLQAAwASiBQAAmEC0AAAAE4gWAABgAtECAABMIFoAAIAJRAsAADCBaAEAACYQLQAAwASiBQAAmEC0AAAAE4gWAABgAtECAABMIFoAAIAJRAsAADCBaAEAACYQLQAAwASiBQAAmEC0AAAAE4gWAABgAtECAABMIFoAAIAJRAsAADCBaAEAACYQLQAAwISOzb3Bp59+WgsXLgy4b+DAgfruu+8kSefPn9cjjzyi1atXq7q6Wunp6XrttdcUFxfX3FMxp88TG5q87vfPZTXjTAAAaHta5ErLjTfeqBMnTvhvn332mX/Zww8/rI8++kgffPCBioqKdPz4cd1zzz0tMQ0AABBCmv1KiyR17NhRHo/nivurqqr0xhtvaNWqVbrrrrskSStWrNDgwYO1fft23XLLLS0xHQAAEAJa5ErLgQMHlJCQoH79+mnatGk6cuSIJKmkpEQ1NTVKS0vzjx00aJB69+6t4uLiBrdXXV0tn88XcAMAAO1Ls0dLSkqKVq5cqY0bN2rp0qUqKyvTHXfcodOnT8vr9SoiIkLR0dEB68TFxcnr9Ta4zfz8fLndbv8tMTGxuacNAADauGZ/eigzM9P/7+HDhyslJUVJSUl6//331aVLlyZtMy8vT7m5uf6PfT4f4QIAQDvT4m95jo6O1oABA3Tw4EF5PB5duHBBlZWVAWPKy8vrfQ3MJZGRkXK5XAE3AADQvrR4tJw5c0aHDh1SfHy8Ro4cqU6dOqmwsNC/vLS0VEeOHFFqampLTwUAABjW7E8PPfroo5owYYKSkpJ0/PhxLViwQB06dNDUqVPldrs1c+ZM5ebmKiYmRi6XSw899JBSU1N55xAAAGhUs0fLsWPHNHXqVJ08eVI9e/bU7bffru3bt6tnz56SpJdfflnh4eGaPHlywC+XAwAAaEyzR8vq1asbXd65c2ctWbJES5Ysae5PDQAAQhh/ewgAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwoWNrTwAAALSMPk9saPK63z+X1YwzaR5caQEAACYQLQAAwASiBQAAmEC0AAAAE4gWAABgAu8eAgy4lncAAECo4EoLAAAwgWgBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYAJveQ4RofZHsQAAuBxXWgAAgAlcaWlm/BIwAABaBldaAACACUQLAAAwgaeHADSIF3gDaEu40gIAAEzgSguAFsFVGgDNjSstAADABKIFAACYwNND4DI+AMAEogUIAoEHAK2Hp4cAAIAJRAsAADCBp4dwTXi6BABwvRAtaHda649a8sc0AQSLx41APD0EAABM4EoLWg3/g0BDLD7taHHOgDVcaQEAACYQLQAAwASeHgKA/4+nLNESOK+aD9ECAK3M4g81XoeD1sDTQwAAwASutAAA2gXe4WUf0QIAwFVYfAovFBEtAICgtdYPca54tG+tGi1LlizRCy+8IK/Xq+TkZC1evFijR49uzSkBMI7/EQOhq9VeiPvee+8pNzdXCxYs0M6dO5WcnKz09HRVVFS01pQAAEAb1mrR8tJLL2nWrFl68MEHNWTIEC1btkxdu3bV8uXLW2tKAACgDWuVp4cuXLigkpIS5eXl+e8LDw9XWlqaiouLrxhfXV2t6upq/8dVVVWSJJ/P1yLzq6s+1yLbBQBcm94Pf9DaU2g3WuJn7KVtOo7TpPVbJVp+/PFH1dbWKi4uLuD+uLg4fffdd1eMz8/P18KFC6+4PzExscXmCABAe+Z+peW2ffr0abnd7qDXM/Huoby8POXm5vo/rqur06lTp9S9e3eFhYU1uq7P51NiYqKOHj0ql8vV0lNt8zgegTgegTgegTgegTgegTgegX7O8XAcR6dPn1ZCQkKTPkerREuPHj3UoUMHlZeXB9xfXl4uj8dzxfjIyEhFRkYG3BcdHR3U53S5XJxUP8HxCMTxCMTxCMTxCMTxCMTxCHS149GUKyyXtMoLcSMiIjRy5EgVFhb676urq1NhYaFSU1NbY0oAAKCNa7Wnh3JzczV9+nTdfPPNGj16tF555RWdPXtWDz74YGtNCQAAtGGtFi333XeffvjhB82fP19er1c33XSTNm7ceMWLc69VZGSkFixYcMXTS+0VxyMQxyMQxyMQxyMQxyMQxyPQ9TgeYU5T33cEAABwHbXaL5cDAAAIBtECAABMIFoAAIAJRAsAADAhJKJlyZIl6tOnjzp37qyUlBR9+eWXjY7/4IMPNGjQIHXu3FnDhg3Txx9/fJ1m2rLy8/M1atQoRUVFKTY2VpMmTVJpaWmj66xcuVJhYWEBt86dO1+nGbesp59++op9GzRoUKPrhOq5IUl9+vS54niEhYUpOzu73vGhdm5s27ZNEyZMUEJCgsLCwrR27dqA5Y7jaP78+YqPj1eXLl2UlpamAwcOXHW7wT7+tBWNHY+amhrNmzdPw4YNU7du3ZSQkKAHHnhAx48fb3SbTfmeayuudn7MmDHjin3LyMi46nZD8fyQVO9jSVhYmF544YUGt9kc54f5aHnvvfeUm5urBQsWaOfOnUpOTlZ6eroqKirqHf/FF19o6tSpmjlzpnbt2qVJkyZp0qRJ2rdv33WeefMrKipSdna2tm/froKCAtXU1GjcuHE6e/Zso+u5XC6dOHHCfzt8+PB1mnHLu/HGGwP27bPPPmtwbCifG5L01VdfBRyLgoICSdIf/vCHBtcJpXPj7NmzSk5O1pIlS+pdvmjRIr366qtatmyZduzYoW7duik9PV3nz59vcJvBPv60JY0dj3Pnzmnnzp166qmntHPnTn344YcqLS3V3XfffdXtBvM915Zc7fyQpIyMjIB9e/fddxvdZqieH5ICjsOJEye0fPlyhYWFafLkyY1u95rPD8e40aNHO9nZ2f6Pa2trnYSEBCc/P7/e8ffee6+TlZUVcF9KSorz17/+tUXn2RoqKiocSU5RUVGDY1asWOG43e7rN6nraMGCBU5ycvLPHt+ezg3HcZy///3vTv/+/Z26urp6l4fyuSHJWbNmjf/juro6x+PxOC+88IL/vsrKSicyMtJ59913G9xOsI8/bdXlx6M+X375pSPJOXz4cINjgv2ea6vqOx7Tp093Jk6cGNR22tP5MXHiROeuu+5qdExznB+mr7RcuHBBJSUlSktL898XHh6utLQ0FRcX17tOcXFxwHhJSk9Pb3C8ZVVVVZKkmJiYRsedOXNGSUlJSkxM1MSJE7V///7rMb3r4sCBA0pISFC/fv00bdo0HTlypMGx7encuHDhgt5++239+c9/bvSPjobyufFTZWVl8nq9AV9/t9utlJSUBr/+TXn8sayqqkphYWFX/btvwXzPWbN161bFxsZq4MCBmjNnjk6ePNng2PZ0fpSXl2vDhg2aOXPmVcde6/lhOlp+/PFH1dbWXvFbdOPi4uT1eutdx+v1BjXeqrq6Os2dO1e33Xabhg4d2uC4gQMHavny5Vq3bp3efvtt1dXV6dZbb9WxY8eu42xbRkpKilauXKmNGzdq6dKlKisr0x133KHTp0/XO769nBuStHbtWlVWVmrGjBkNjgnlc+Nyl77GwXz9m/L4Y9X58+c1b948TZ06tdE/hBfs95wlGRkZeuutt1RYWKjnn39eRUVFyszMVG1tbb3j29P58eabbyoqKkr33HNPo+Oa4/xotV/jj5aVnZ2tffv2XfX5wtTU1IA/Unnrrbdq8ODBev311/Xss8+29DRbVGZmpv/fw4cPV0pKipKSkvT+++//rP8RhLI33nhDmZmZjf55+FA+N/Dz1dTU6N5775XjOFq6dGmjY0P5e27KlCn+fw8bNkzDhw9X//79tXXrVo0dO7YVZ9b6li9frmnTpl31hfrNcX6YvtLSo0cPdejQQeXl5QH3l5eXy+Px1LuOx+MJarxFOTk5Wr9+vbZs2aJevXoFtW6nTp00YsQIHTx4sIVm13qio6M1YMCABvetPZwbknT48GFt2rRJf/nLX4JaL5TPjUtf42C+/k15/LHmUrAcPnxYBQUFjV5lqc/Vvucs69evn3r06NHgvrWH80OSPv30U5WWlgb9eCI17fwwHS0REREaOXKkCgsL/ffV1dWpsLAw4H+IP5WamhowXpIKCgoaHG+J4zjKycnRmjVrtHnzZvXt2zfobdTW1mrv3r2Kj49vgRm2rjNnzujQoUMN7lsonxs/tWLFCsXGxiorKyuo9UL53Ojbt688Hk/A19/n82nHjh0Nfv2b8vhjyaVgOXDggDZt2qTu3bsHvY2rfc9ZduzYMZ08ebLBfQv18+OSN954QyNHjlRycnLQ6zbp/Liml/G2AatXr3YiIyOdlStXOt98840ze/ZsJzo62vF6vY7jOM7999/vPPHEE/7xn3/+udOxY0fnxRdfdL799ltnwYIFTqdOnZy9e/e21i40mzlz5jhut9vZunWrc+LECf/t3Llz/jGXH4+FCxc6n3zyiXPo0CGnpKTEmTJlitO5c2dn//79rbELzeqRRx5xtm7d6pSVlTmff/65k5aW5vTo0cOpqKhwHKd9nRuX1NbWOr1793bmzZt3xbJQPzdOnz7t7Nq1y9m1a5cjyXnppZecXbt2+d8N89xzzznR0dHOunXrnD179jgTJ050+vbt6/zvf//zb+Ouu+5yFi9e7P/4ao8/bVljx+PChQvO3Xff7fTq1cvZvXt3wONJdXW1fxuXH4+rfc+1ZY0dj9OnTzuPPvqoU1xc7JSVlTmbNm1yfv3rXzs33HCDc/78ef822sv5cUlVVZXTtWtXZ+nSpfVuoyXOD/PR4jiOs3jxYqd3795ORESEM3r0aGf79u3+Zb/5zW+c6dOnB4x///33nQEDBjgRERHOjTfe6GzYsOE6z7hlSKr3tmLFCv+Yy4/H3Llz/ccuLi7OGT9+vLNz587rP/kWcN999znx8fFORESE88tf/tK57777nIMHD/qXt6dz45JPPvnEkeSUlpZesSzUz40tW7bU+/1xaZ/r6uqcp556yomLi3MiIyOdsWPHXnGckpKSnAULFgTc19jjT1vW2PEoKytr8PFky5Yt/m1cfjyu9j3XljV2PM6dO+eMGzfO6dmzp9OpUycnKSnJmTVr1hXx0V7Oj0tef/11p0uXLk5lZWW922iJ8yPMcRwn6Gs6AAAA15np17QAAID2g2gBAAAmEC0AAMAEogUAAJhAtAAAABOIFgAAYALRAgAATCBaAACACUQLAAAwgWgBAAAmEC0AAMAEogUAAJjwf//JgQAjgZGeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_equity['class_temp'],bins=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
